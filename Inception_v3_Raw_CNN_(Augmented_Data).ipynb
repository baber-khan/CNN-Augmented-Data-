{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_v3 - Raw - CNN (Augmented Data).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz_tma7gAlsn",
        "colab_type": "code",
        "outputId": "30ce93e8-3351-4834-eb84-af3cd6e0c74e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "Drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RICAeU1MAsVT",
        "colab_type": "code",
        "outputId": "06ff94b4-11e1-4ecd-9343-25784fdbf292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('/content/Drive/My Drive/Colab Notebooks/Augmented1')\n",
        "\n",
        "!ls  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " history.json\t\t\t       Test\t    vgg16_2.h5\n",
            "'Raw VGG16.h5'\t\t\t       Training     weights.best.hdf5\n",
            "'Rotated - VGG - CNN(Augmented1).h5'   Validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfJp_AX0AvXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.applications import inception_v3\n",
        "\n",
        "#Load the Inception_V3 model\n",
        "conv_base = inception_v3.InceptionV3(weights='imagenet',\n",
        "                                           include_top = False,\n",
        "                                           input_shape=(150,150,3)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNFzRnG6A17D",
        "colab_type": "code",
        "outputId": "b8e986ed-5003-407d-e7d9-22c2a2332d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 74, 74, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 74, 74, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 32)   9216        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 32)   96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 32)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 72, 72, 64)   18432       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 72, 72, 64)   192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 72, 72, 64)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 35, 35, 80)   240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 35, 35, 80)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 33, 33, 192)  138240      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 33, 33, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 33, 33, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   55296       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 48)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   76800       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 96)   82944       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 64)   192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 32)   96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 96)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 32)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_100[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 64)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   55296       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 48)   144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 48)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   76800       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 96)   82944       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 64)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 96)   288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 96)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 64)   192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   55296       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 48)   144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 48)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   76800       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 96)   82944       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 64)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 96)   288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 64)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 96)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_114[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 64)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 96)   55296       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 96)     82944       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 7, 7, 384)    1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 96)     288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 7, 7, 384)    0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 96)     0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 128)    114688      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 128)    114688      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 128)    384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 128)    384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 128)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 128)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 192)    172032      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    172032      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 160)    179200      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 160)    179200      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 160)    480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 160)    480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 160)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 160)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 192)    215040      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 192)    576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 192)    576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 192)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 192)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_135[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 160)    179200      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 160)    179200      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 160)    480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 160)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    215040      activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    258048      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    258048      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_155[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 7, 7, 192)    258048      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 7, 7, 192)    576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 7, 7, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 7, 7, 192)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 7, 7, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 3, 3, 320)    552960      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 192)    331776      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 3, 3, 320)    960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 192)    576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 3, 3, 320)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 192)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_166[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 448)    1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 448)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    1548288     activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 384)    1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 384)    1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 384)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 384)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_173[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_177[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 192)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_171[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 448)    1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 448)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    1548288     activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 384)    1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 384)    1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 320)    960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 384)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 384)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 320)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_180[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_188[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-miyhY8A558",
        "colab_type": "code",
        "outputId": "b2c13c92-5032-4ee8-da33-f145293cd3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir ='/content/Drive/My Drive/Colab Notebooks/Augmented1'\n",
        "train_dir = os.path.join(base_dir, 'Training')\n",
        "validation_dir = os.path.join(base_dir, 'Validation')\n",
        "test_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 10\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 3, 3, 2048))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    i=0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "train_features, train_labels = extract_features(train_dir, 2597)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1558)\n",
        "test_features, test_labels = extract_features(test_dir, 1045)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2597 images belonging to 2 classes.\n",
            "Found 1558 images belonging to 2 classes.\n",
            "Found 1045 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxVqY_cGGgFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = np.reshape(train_features, (2597, 3*3* 2048))\n",
        "validation_features = np.reshape(validation_features, (1558, 3*3* 2048))\n",
        "test_features = np.reshape(test_features, (1045, 3*3* 2048))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp2-qEGYBBag",
        "colab_type": "code",
        "outputId": "ebb0b700-b374-4940-8f69-237457b56394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim= 3*3* 2048))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "loss='binary_crossentropy',\n",
        "metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "epochs=100,\n",
        "batch_size=20,\n",
        "validation_data=(validation_features, validation_labels)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2597 samples, validate on 1558 samples\n",
            "Epoch 1/100\n",
            "2597/2597 [==============================] - 3s 1ms/step - loss: 0.7466 - acc: 0.5945 - val_loss: 0.5908 - val_acc: 0.6849\n",
            "Epoch 2/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 0.5665 - acc: 0.7074 - val_loss: 0.5628 - val_acc: 0.7144\n",
            "Epoch 3/100\n",
            "2597/2597 [==============================] - 1s 384us/step - loss: 0.4773 - acc: 0.7720 - val_loss: 0.4830 - val_acc: 0.7779\n",
            "Epoch 4/100\n",
            "2597/2597 [==============================] - 1s 395us/step - loss: 0.3977 - acc: 0.8271 - val_loss: 0.4563 - val_acc: 0.7965\n",
            "Epoch 5/100\n",
            "2597/2597 [==============================] - 1s 400us/step - loss: 0.3385 - acc: 0.8729 - val_loss: 0.4271 - val_acc: 0.8190\n",
            "Epoch 6/100\n",
            "2597/2597 [==============================] - 1s 394us/step - loss: 0.2863 - acc: 0.8976 - val_loss: 0.3921 - val_acc: 0.8408\n",
            "Epoch 7/100\n",
            "2597/2597 [==============================] - 1s 404us/step - loss: 0.2524 - acc: 0.9122 - val_loss: 0.3644 - val_acc: 0.8511\n",
            "Epoch 8/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 0.2071 - acc: 0.9392 - val_loss: 0.3636 - val_acc: 0.8479\n",
            "Epoch 9/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 0.1844 - acc: 0.9484 - val_loss: 0.3245 - val_acc: 0.8684\n",
            "Epoch 10/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 0.1581 - acc: 0.9603 - val_loss: 0.3326 - val_acc: 0.8562\n",
            "Epoch 11/100\n",
            "2597/2597 [==============================] - 1s 397us/step - loss: 0.1435 - acc: 0.9692 - val_loss: 0.3116 - val_acc: 0.8684\n",
            "Epoch 12/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 0.1236 - acc: 0.9696 - val_loss: 0.2978 - val_acc: 0.8761\n",
            "Epoch 13/100\n",
            "2597/2597 [==============================] - 1s 386us/step - loss: 0.1058 - acc: 0.9777 - val_loss: 0.2913 - val_acc: 0.8851\n",
            "Epoch 14/100\n",
            "2597/2597 [==============================] - 1s 397us/step - loss: 0.0917 - acc: 0.9827 - val_loss: 0.3059 - val_acc: 0.8774\n",
            "Epoch 15/100\n",
            "2597/2597 [==============================] - 1s 394us/step - loss: 0.0800 - acc: 0.9900 - val_loss: 0.3335 - val_acc: 0.8665\n",
            "Epoch 16/100\n",
            "2597/2597 [==============================] - 1s 390us/step - loss: 0.0715 - acc: 0.9892 - val_loss: 0.2757 - val_acc: 0.8858\n",
            "Epoch 17/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 0.0609 - acc: 0.9938 - val_loss: 0.2611 - val_acc: 0.8922\n",
            "Epoch 18/100\n",
            "2597/2597 [==============================] - 1s 399us/step - loss: 0.0584 - acc: 0.9908 - val_loss: 0.2655 - val_acc: 0.8915\n",
            "Epoch 19/100\n",
            "2597/2597 [==============================] - 1s 398us/step - loss: 0.0466 - acc: 0.9954 - val_loss: 0.2535 - val_acc: 0.9018\n",
            "Epoch 20/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 0.0426 - acc: 0.9942 - val_loss: 0.2811 - val_acc: 0.8909\n",
            "Epoch 21/100\n",
            "2597/2597 [==============================] - 1s 400us/step - loss: 0.0386 - acc: 0.9969 - val_loss: 0.2650 - val_acc: 0.8947\n",
            "Epoch 22/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 0.0320 - acc: 0.9988 - val_loss: 0.2529 - val_acc: 0.8954\n",
            "Epoch 23/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 0.0282 - acc: 0.9981 - val_loss: 0.2574 - val_acc: 0.8979\n",
            "Epoch 24/100\n",
            "2597/2597 [==============================] - 1s 398us/step - loss: 0.0251 - acc: 0.9985 - val_loss: 0.2774 - val_acc: 0.8941\n",
            "Epoch 25/100\n",
            "2597/2597 [==============================] - 1s 390us/step - loss: 0.0239 - acc: 0.9981 - val_loss: 0.2557 - val_acc: 0.9018\n",
            "Epoch 26/100\n",
            "2597/2597 [==============================] - 1s 402us/step - loss: 0.0203 - acc: 0.9992 - val_loss: 0.2619 - val_acc: 0.9005\n",
            "Epoch 27/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 0.0184 - acc: 0.9988 - val_loss: 0.2602 - val_acc: 0.9012\n",
            "Epoch 28/100\n",
            "2597/2597 [==============================] - 1s 394us/step - loss: 0.0157 - acc: 0.9996 - val_loss: 0.2695 - val_acc: 0.8979\n",
            "Epoch 29/100\n",
            "2597/2597 [==============================] - 1s 399us/step - loss: 0.0134 - acc: 0.9992 - val_loss: 0.2675 - val_acc: 0.8992\n",
            "Epoch 30/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 0.0136 - acc: 0.9992 - val_loss: 0.2649 - val_acc: 0.9024\n",
            "Epoch 31/100\n",
            "2597/2597 [==============================] - 1s 401us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2638 - val_acc: 0.9031\n",
            "Epoch 32/100\n",
            "2597/2597 [==============================] - 1s 395us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.8967\n",
            "Epoch 33/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 0.0090 - acc: 0.9996 - val_loss: 0.2898 - val_acc: 0.9005\n",
            "Epoch 34/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 0.0084 - acc: 0.9996 - val_loss: 0.2758 - val_acc: 0.9005\n",
            "Epoch 35/100\n",
            "2597/2597 [==============================] - 1s 404us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.2789 - val_acc: 0.9056\n",
            "Epoch 36/100\n",
            "2597/2597 [==============================] - 1s 390us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2880 - val_acc: 0.9012\n",
            "Epoch 37/100\n",
            "2597/2597 [==============================] - 1s 382us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.2714 - val_acc: 0.9044\n",
            "Epoch 38/100\n",
            "2597/2597 [==============================] - 1s 400us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.2844 - val_acc: 0.9012\n",
            "Epoch 39/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.2818 - val_acc: 0.9031\n",
            "Epoch 40/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 0.9076\n",
            "Epoch 41/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2860 - val_acc: 0.9082\n",
            "Epoch 42/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2913 - val_acc: 0.9082\n",
            "Epoch 43/100\n",
            "2597/2597 [==============================] - 1s 386us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.2874 - val_acc: 0.9108\n",
            "Epoch 44/100\n",
            "2597/2597 [==============================] - 1s 401us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3201 - val_acc: 0.8992\n",
            "Epoch 45/100\n",
            "2597/2597 [==============================] - 1s 406us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3011 - val_acc: 0.9063\n",
            "Epoch 46/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3013 - val_acc: 0.9089\n",
            "Epoch 47/100\n",
            "2597/2597 [==============================] - 1s 394us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.3099 - val_acc: 0.9056\n",
            "Epoch 48/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3126 - val_acc: 0.9050\n",
            "Epoch 49/100\n",
            "2597/2597 [==============================] - 1s 399us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.9050\n",
            "Epoch 50/100\n",
            "2597/2597 [==============================] - 1s 386us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.9050\n",
            "Epoch 51/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 0.9050\n",
            "Epoch 52/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3544 - val_acc: 0.9031\n",
            "Epoch 53/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.9108\n",
            "Epoch 54/100\n",
            "2597/2597 [==============================] - 1s 401us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3388 - val_acc: 0.9018\n",
            "Epoch 55/100\n",
            "2597/2597 [==============================] - 1s 404us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.3248 - val_acc: 0.9076\n",
            "Epoch 56/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 9.5737e-04 - acc: 1.0000 - val_loss: 0.3349 - val_acc: 0.9114\n",
            "Epoch 57/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 8.8522e-04 - acc: 1.0000 - val_loss: 0.3282 - val_acc: 0.9134\n",
            "Epoch 58/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 6.8301e-04 - acc: 1.0000 - val_loss: 0.3366 - val_acc: 0.9134\n",
            "Epoch 59/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 9.6184e-04 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 0.9121\n",
            "Epoch 60/100\n",
            "2597/2597 [==============================] - 1s 387us/step - loss: 6.5199e-04 - acc: 1.0000 - val_loss: 0.3412 - val_acc: 0.9114\n",
            "Epoch 61/100\n",
            "2597/2597 [==============================] - 1s 397us/step - loss: 5.7065e-04 - acc: 1.0000 - val_loss: 0.3853 - val_acc: 0.9005\n",
            "Epoch 62/100\n",
            "2597/2597 [==============================] - 1s 395us/step - loss: 7.8006e-04 - acc: 1.0000 - val_loss: 0.3520 - val_acc: 0.9089\n",
            "Epoch 63/100\n",
            "2597/2597 [==============================] - 1s 401us/step - loss: 4.5515e-04 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.9114\n",
            "Epoch 64/100\n",
            "2597/2597 [==============================] - 1s 401us/step - loss: 6.2502e-04 - acc: 1.0000 - val_loss: 0.3789 - val_acc: 0.9063\n",
            "Epoch 65/100\n",
            "2597/2597 [==============================] - 1s 404us/step - loss: 3.9210e-04 - acc: 1.0000 - val_loss: 0.3779 - val_acc: 0.9082\n",
            "Epoch 66/100\n",
            "2597/2597 [==============================] - 1s 399us/step - loss: 4.4396e-04 - acc: 1.0000 - val_loss: 0.3631 - val_acc: 0.9056\n",
            "Epoch 67/100\n",
            "2597/2597 [==============================] - 1s 384us/step - loss: 3.3952e-04 - acc: 1.0000 - val_loss: 0.3745 - val_acc: 0.9114\n",
            "Epoch 68/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 6.3031e-04 - acc: 1.0000 - val_loss: 0.3606 - val_acc: 0.9140\n",
            "Epoch 69/100\n",
            "2597/2597 [==============================] - 1s 387us/step - loss: 4.4268e-04 - acc: 1.0000 - val_loss: 0.3805 - val_acc: 0.9076\n",
            "Epoch 70/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 2.6599e-04 - acc: 1.0000 - val_loss: 0.3750 - val_acc: 0.9127\n",
            "Epoch 71/100\n",
            "2597/2597 [==============================] - 1s 390us/step - loss: 2.2264e-04 - acc: 1.0000 - val_loss: 0.3742 - val_acc: 0.9178\n",
            "Epoch 72/100\n",
            "2597/2597 [==============================] - 1s 394us/step - loss: 2.4825e-04 - acc: 1.0000 - val_loss: 0.3924 - val_acc: 0.9063\n",
            "Epoch 73/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 1.8899e-04 - acc: 1.0000 - val_loss: 0.3868 - val_acc: 0.9095\n",
            "Epoch 74/100\n",
            "2597/2597 [==============================] - 1s 386us/step - loss: 1.4569e-04 - acc: 1.0000 - val_loss: 0.3956 - val_acc: 0.9114\n",
            "Epoch 75/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 1.7090e-04 - acc: 1.0000 - val_loss: 0.4093 - val_acc: 0.9076\n",
            "Epoch 76/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 1.7270e-04 - acc: 1.0000 - val_loss: 0.3824 - val_acc: 0.9121\n",
            "Epoch 77/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 1.4462e-04 - acc: 1.0000 - val_loss: 0.4049 - val_acc: 0.9101\n",
            "Epoch 78/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 1.5530e-04 - acc: 1.0000 - val_loss: 0.3992 - val_acc: 0.9121\n",
            "Epoch 79/100\n",
            "2597/2597 [==============================] - 1s 387us/step - loss: 1.1728e-04 - acc: 1.0000 - val_loss: 0.4030 - val_acc: 0.9134\n",
            "Epoch 80/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 1.2048e-04 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.9127\n",
            "Epoch 81/100\n",
            "2597/2597 [==============================] - 1s 388us/step - loss: 1.1838e-04 - acc: 1.0000 - val_loss: 0.4026 - val_acc: 0.9127\n",
            "Epoch 82/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 1.1945e-04 - acc: 1.0000 - val_loss: 0.4220 - val_acc: 0.9101\n",
            "Epoch 83/100\n",
            "2597/2597 [==============================] - 1s 390us/step - loss: 9.4345e-05 - acc: 1.0000 - val_loss: 0.4129 - val_acc: 0.9159\n",
            "Epoch 84/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 1.1216e-04 - acc: 1.0000 - val_loss: 0.4335 - val_acc: 0.9127\n",
            "Epoch 85/100\n",
            "2597/2597 [==============================] - 1s 387us/step - loss: 8.4250e-05 - acc: 1.0000 - val_loss: 0.4208 - val_acc: 0.9153\n",
            "Epoch 86/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 9.7758e-05 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.9146\n",
            "Epoch 87/100\n",
            "2597/2597 [==============================] - 1s 393us/step - loss: 1.0902e-04 - acc: 1.0000 - val_loss: 0.4152 - val_acc: 0.9114\n",
            "Epoch 88/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 7.0661e-05 - acc: 1.0000 - val_loss: 0.4267 - val_acc: 0.9127\n",
            "Epoch 89/100\n",
            "2597/2597 [==============================] - 1s 402us/step - loss: 1.3102e-04 - acc: 1.0000 - val_loss: 0.4351 - val_acc: 0.9146\n",
            "Epoch 90/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 5.1850e-05 - acc: 1.0000 - val_loss: 0.4499 - val_acc: 0.9108\n",
            "Epoch 91/100\n",
            "2597/2597 [==============================] - 1s 389us/step - loss: 6.3298e-05 - acc: 1.0000 - val_loss: 0.4579 - val_acc: 0.9069\n",
            "Epoch 92/100\n",
            "2597/2597 [==============================] - 1s 397us/step - loss: 4.2522e-05 - acc: 1.0000 - val_loss: 0.4499 - val_acc: 0.9063\n",
            "Epoch 93/100\n",
            "2597/2597 [==============================] - 1s 396us/step - loss: 3.8388e-05 - acc: 1.0000 - val_loss: 0.5114 - val_acc: 0.9012\n",
            "Epoch 94/100\n",
            "2597/2597 [==============================] - 1s 377us/step - loss: 1.0988e-04 - acc: 1.0000 - val_loss: 0.4499 - val_acc: 0.9114\n",
            "Epoch 95/100\n",
            "2597/2597 [==============================] - 1s 387us/step - loss: 3.8289e-05 - acc: 1.0000 - val_loss: 0.4550 - val_acc: 0.9108\n",
            "Epoch 96/100\n",
            "2597/2597 [==============================] - 1s 398us/step - loss: 3.5829e-05 - acc: 1.0000 - val_loss: 0.4484 - val_acc: 0.9166\n",
            "Epoch 97/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 4.5800e-05 - acc: 1.0000 - val_loss: 0.4529 - val_acc: 0.9134\n",
            "Epoch 98/100\n",
            "2597/2597 [==============================] - 1s 392us/step - loss: 3.6147e-05 - acc: 1.0000 - val_loss: 0.4688 - val_acc: 0.9044\n",
            "Epoch 99/100\n",
            "2597/2597 [==============================] - 1s 391us/step - loss: 2.9223e-05 - acc: 1.0000 - val_loss: 0.4405 - val_acc: 0.9127\n",
            "Epoch 100/100\n",
            "2597/2597 [==============================] - 1s 400us/step - loss: 5.3846e-05 - acc: 1.0000 - val_loss: 0.4427 - val_acc: 0.9127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdYGJv7LBJu2",
        "colab_type": "code",
        "outputId": "2e7908ff-f634-40ff-fb34-7a1720730f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQM1zoq8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU5dn48e/NLotsUhe2oIIQBFki\nYlFZtbhBUbQg4i6Kolbl16JYq1jeqi+lLsUFFawSQeqKglJbsOqrIoEiiIjsEECEIFEEhZD798c9\nQyZhksyQmUxmcn+ua67MOfPMOc/JSe555llFVXHOOZf8qiQ6A84552LDA7pzzqUID+jOOZciPKA7\n51yK8IDunHMpwgO6c86lCA/oLiwRqSoiu0WkRSzTJpKInCgiMe+nKyL9RGR9yPZKETkzkrSHca5n\nReTuw31/Ccf9k4g8H+vjuvJVLdEZcLEhIrtDNmsDPwMHAts3qGpmNMdT1QNA3VinrQxU9aRYHEdE\nrgMuV9VeIce+LhbHdqnJA3qKUNWDATVQArxOVf9VXHoRqaaqeeWRN+dc+fAql0oi8JX6ZRGZLiI/\nAJeLyOki8qmI7BKRrSLymIhUD6SvJiIqImmB7WmB198RkR9E5BMRaRVt2sDr54rI1yKSKyKPi8j/\nichVxeQ7kjzeICKrReQ7EXks5L1VReSvIpIjImuB/iX8fsaKyIwi+yaJyMTA8+tEZEXgetYESs/F\nHStbRHoFntcWkRcDeVsOdC2S9h4RWRs47nIRGRDY3wH4G3BmoDprR8jv9r6Q998YuPYcEXlDRI6N\n5HdTGhEZFMjPLhGZJyInhbx2t4hsEZHvReSrkGvtLiKLA/u3icj/Rno+FyOq6o8UewDrgX5F9v0J\n2AdciH2QHwGcCpyGfVM7HvgaGBVIXw1QIC2wPQ3YAWQA1YGXgWmHkfYXwA/AwMBrdwD7gauKuZZI\n8vgmUB9IA3YGrx0YBSwHmgGNgQ/sTz7seY4HdgN1Qo79LZAR2L4wkEaAPsBeoGPgtX7A+pBjZQO9\nAs8nAO8DDYGWwJdF0l4KHBu4J5cF8nB04LXrgPeL5HMacF/g+TmBPHYCagFPAPMi+d2Euf4/Ac8H\nnrcL5KNP4B7dDawMPG8PbACOCaRtBRwfeL4QGBp4Xg84LdH/C5Xt4SX0yuUjVX1LVfNVda+qLlTV\nBaqap6prgclAzxLe/4qqZqnqfiATCyTRpr0AWKKqbwZe+ysW/MOKMI9/VtVcVV2PBc/guS4F/qqq\n2aqaAzxYwnnWAl9gHzQAZwPfqWpW4PW3VHWtmnnAv4GwDZ9FXAr8SVW/U9UNWKk79LwzVXVr4J68\nhH0YZ0RwXIBhwLOqukRVfwLGAD1FpFlImuJ+NyUZAsxS1XmBe/Qg9qFwGpCHfXi0D1TbrQv87sA+\nmFuLSGNV/UFVF0R4HS5GPKBXLptCN0SkrYjMFpFvROR7YBxwVAnv/ybk+R5KbggtLu1xoflQVcVK\ntGFFmMeIzoWVLEvyEjA08PyywHYwHxeIyAIR2Skiu7DScUm/q6BjS8qDiFwlIp8HqjZ2AW0jPC7Y\n9R08nqp+D3wHNA1JE809K+64+dg9aqqqK4E7sfvwbaAK75hA0quBdGCliHwmIudFeB0uRjygVy5F\nu+w9jZVKT1TVI4F7sSqFeNqKVYEAICJC4QBUVFnyuBVoHrJdWrfKmUA/EWmKldRfCuTxCOAV4M9Y\ndUgD4J8R5uOb4vIgIscDTwIjgcaB434VctzSulhuwapxgserh1XtbI4gX9Ectwp2zzYDqOo0Ve2B\nVbdUxX4vqOpKVR2CVav9BXhVRGqVMS8uCh7QK7d6QC7wo4i0A24oh3O+DXQRkQtFpBpwG9AkTnmc\nCfxWRJqKSGPg9yUlVtVvgI+A54GVqroq8FJNoAawHTggIhcAfaPIw90i0kCsn/6okNfqYkF7O/bZ\ndj1WQg/aBjQLNgKHMR24VkQ6ikhNLLB+qKrFfuOJIs8DRKRX4Nz/D2v3WCAi7USkd+B8ewOPfOwC\nhovIUYESfW7g2vLLmBcXBQ/oldudwJXYP+vTWONlXKnqNuA3wEQgBzgB+C/Wbz7WeXwSq+tehjXY\nvRLBe17CGjkPVreo6i7gduB1rGFxMPbBFIk/Yt8U1gPvAC+EHHcp8DjwWSDNSUBovfN7wCpgm4iE\nVp0E3/8uVvXxeuD9LbB69TJR1eXY7/xJ7MOmPzAgUJ9eE3gYa/f4BvtGMDbw1vOAFWK9qCYAv1HV\nfWXNj4ucWBWmc4khIlWxr/iDVfXDROfHuWTmJXRX7kSkf6AKoibwB6x3xGcJzpZzSc8DukuEM4C1\n2Nf5XwGDVLW4KhfnXIS8ysU551KEl9Cdcy5FJGxyrqOOOkrT0tISdXrnnEtKixYt2qGqYbv6Jiyg\np6WlkZWVlajTO+dcUhKRYkc8e5WLc86lCA/ozjmXIjygO+dcivAVi5yrJPbv3092djY//fRTorPi\nIlCrVi2aNWtG9erFTeVzKA/ozlUS2dnZ1KtXj7S0NGySS1dRqSo5OTlkZ2fTqlWr0t8QkFRVLpmZ\nkJYGVarYz8yolj12rnL76aefaNy4sQfzJCAiNG7cOOpvU0lTQs/MhBEjYM8e296wwbYBhpV5fjnn\nKgcP5snjcO5V0pTQx44tCOZBe/bYfuecc0kU0DdujG6/c65iycnJoVOnTnTq1IljjjmGpk2bHtze\nty+yadOvvvpqVq5cWWKaSZMmkRmj+tgzzjiDJUuWxORY5SFpqlxatLBqlnD7nXOxl5lp34A3brT/\ns/Hjy1a92bhx44PB8b777qNu3bqMHj26UJqDq9dXCV/WnDp1aqnnufnmmw8/k0kuaUro48dD7dqF\n99Wubfudc7EVbLPasAFUC9qs4tERYfXq1aSnpzNs2DDat2/P1q1bGTFiBBkZGbRv355x48YdTBss\nMefl5dGgQQPGjBnDKaecwumnn863334LwD333MMjjzxyMP2YMWPo1q0bJ510Eh9//DEAP/74Ixdf\nfDHp6ekMHjyYjIyMUkvi06ZNo0OHDpx88sncfffdAOTl5TF8+PCD+x977DEA/vrXv5Kenk7Hjh25\n/PLLY/47K07SlNCDJYNYlhicc+GV1GYVj/+5r776ihdeeIGMjAwAHnzwQRo1akReXh69e/dm8ODB\npKenF3pPbm4uPXv25MEHH+SOO+5gypQpjBkz5pBjqyqfffYZs2bNYty4cbz77rs8/vjjHHPMMbz6\n6qt8/vnndOnSpcT8ZWdnc88995CVlUX9+vXp168fb7/9Nk2aNGHHjh0sW7YMgF27dgHw8MMPs2HD\nBmrUqHFwX3lImhI62B/S+vWQn28/PZg7Fx/l3WZ1wgknHAzmANOnT6dLly506dKFFStW8OWXXx7y\nniOOOIJzzz0XgK5du7J+/fqwx77ooosOSfPRRx8xZMgQAE455RTat29fYv4WLFhAnz59OOqoo6he\nvTqXXXYZH3zwASeeeCIrV67k1ltvZe7cudSvXx+A9u3bc/nll5OZmRnVwKCySqqA7pwrH8W1TcWr\nzapOnToHn69atYpHH32UefPmsXTpUvr37x+2P3aNGjUOPq9atSp5eXlhj12zZs1S0xyuxo0bs3Tp\nUs4880wmTZrEDTfcAMDcuXO58cYbWbhwId26dePAgQMxPW9xPKA75w6RyDar77//nnr16nHkkUey\ndetW5s6dG/Nz9OjRg5kzZwKwbNmysN8AQp122mnMnz+fnJwc8vLymDFjBj179mT79u2oKpdccgnj\nxo1j8eLFHDhwgOzsbPr06cPDDz/Mjh072FO0/ipOkqYO3TlXfhLZZtWlSxfS09Np27YtLVu2pEeP\nHjE/xy233MIVV1xBenr6wUewuiScZs2a8cADD9CrVy9UlQsvvJDzzz+fxYsXc+2116KqiAgPPfQQ\neXl5XHbZZfzwww/k5+czevRo6tWrF/NrCCdha4pmZGSoL3DhXPlZsWIF7dq1S3Q2KoS8vDzy8vKo\nVasWq1at4pxzzmHVqlVUq1axyrjh7pmILFLVjHDpI8q9iPQHHgWqAs+q6oNFXv8r0DuwWRv4hao2\niDLvzjlXLnbv3k3fvn3Jy8tDVXn66acrXDA/HKVegYhUBSYBZwPZwEIRmaWqByudVPX2kPS3AJ3j\nkFfnnIuJBg0asGjRokRnI+YiaRTtBqxW1bWqug+YAQwsIf1QYHosMueccy5ykQT0psCmkO3swL5D\niEhLoBUwr+xZc845F41Yd1scAryiqmE7XYrICBHJEpGs7du3x/jUzjlXuUUS0DcDzUO2mwX2hTOE\nEqpbVHWyqmaoakaTJk0iz6VzzrlSRRLQFwKtRaSViNTAgvasoolEpC3QEPgktll0zqWC3r17HzJI\n6JFHHmHkyJElvq9u3boAbNmyhcGDB4dN06tXL0rrBv3II48UGuBz3nnnxWSelfvuu48JEyaU+Tix\nUGpAV9U8YBQwF1gBzFTV5SIyTkQGhCQdAszQRHVsd85VaEOHDmXGjBmF9s2YMYOhQ4dG9P7jjjuO\nV1555bDPXzSgz5kzhwYNUqt3dUR16Ko6R1XbqOoJqjo+sO9eVZ0VkuY+VT10qjPnnAMGDx7M7Nmz\nDy5msX79erZs2cKZZ555sF94ly5d6NChA2+++eYh71+/fj0nn3wyAHv37mXIkCG0a9eOQYMGsXfv\n3oPpRo4ceXDq3T/+8Y8APPbYY2zZsoXevXvTu7cNmUlLS2PHjh0ATJw4kZNPPpmTTz754NS769ev\np127dlx//fW0b9+ec845p9B5wlmyZAndu3enY8eODBo0iO++++7g+YPT6QYnBfvPf/5zcIGPzp07\n88MPPxz27zYo+XvSO+ei9tvfQqwX4unUCQKxMKxGjRrRrVs33nnnHQYOHMiMGTO49NJLERFq1arF\n66+/zpFHHsmOHTvo3r07AwYMKHZdzSeffJLatWuzYsUKli5dWmj62/Hjx9OoUSMOHDhA3759Wbp0\nKbfeeisTJ05k/vz5HHXUUYWOtWjRIqZOncqCBQtQVU477TR69uxJw4YNWbVqFdOnT+eZZ57h0ksv\n5dVXXy1xfvMrrriCxx9/nJ49e3Lvvfdy//3388gjj/Dggw+ybt06atasebCaZ8KECUyaNIkePXqw\ne/duatWqFcVvOzyfnMs5V25Cq11Cq1tUlbvvvpuOHTvSr18/Nm/ezLZt24o9zgcffHAwsHbs2JGO\nHTsefG3mzJl06dKFzp07s3z58lIn3vroo48YNGgQderUoW7dulx00UV8+OGHALRq1YpOnToBJU/R\nCzY/+65du+jZsycAV155JR988MHBPA4bNoxp06YdHJHao0cP7rjjDh577DF27doVk5GqXkJ3rhIq\nqSQdTwMHDuT2229n8eLF7Nmzh65duwKQmZnJ9u3bWbRoEdWrVyctLS3slLmlWbduHRMmTGDhwoU0\nbNiQq6666rCOExScehds+t3SqlyKM3v2bD744APeeustxo8fz7JlyxgzZgznn38+c+bMoUePHsyd\nO5e2bdsedl7BS+jOuXJUt25devfuzTXXXFOoMTQ3N5df/OIXVK9enfnz57Mh3ALCIc466yxeeukl\nAL744guWLl0K2NS7derUoX79+mzbto133nnn4Hvq1asXtp76zDPP5I033mDPnj38+OOPvP7665x5\n5plRX1v9+vVp2LDhwdL9iy++SM+ePcnPz2fTpk307t2bhx56iNzcXHbv3s2aNWvo0KEDv//97zn1\n1FP56quvoj5nUV5Cd86Vq6FDhzJo0KBCPV6GDRvGhRdeSIcOHcjIyCi1pDpy5Eiuvvpq2rVrR7t2\n7Q6W9E855RQ6d+5M27Ztad68eaGpd0eMGEH//v057rjjmD9//sH9Xbp04aqrrqJbt24AXHfddXTu\n3LnE6pXi/P3vf+fGG29kz549HH/88UydOpUDBw5w+eWXk5ubi6py66230qBBA/7whz8wf/58qlSp\nQvv27Q+uvlQWPn2uc5WET5+bfKKdPterXJxzLkV4QHfOuRThAd25SsQHciePw7lXHtCdqyRq1apF\nTk6OB/UkoKrk5OREPdjIe7k4V0k0a9aM7OxsfOrq5FCrVi2aNWsW1Xs8oDtXSVSvXp1WrVolOhsu\njrzKxTnnUoQHdOecSxEe0J1zLkV4QHfOuRThAd0551KEB3TnnEsREQV0EekvIitFZLWIhF1mTkQu\nFZEvRWS5iLwU22w655wrTan90EWkKjAJOBvIBhaKyCxV/TIkTWvgLqCHqn4nIr+IV4adc86FF0kJ\nvRuwWlXXquo+YAYwsEia64FJqvodgKp+G9tsOuecK00kAb0psClkOzuwL1QboI2I/J+IfCoi/cMd\nSERGiEiWiGT58GPnnIutWDWKVgNaA72AocAzItKgaCJVnayqGaqa0aRJk8M60fffw9tvlyWrzjmX\nmiIJ6JuB5iHbzQL7QmUDs1R1v6quA77GAnzMTZgAAwbAYawO5ZxzKS2SgL4QaC0irUSkBjAEmFUk\nzRtY6RwROQqrglkbw3wedN11IAKTJ8fj6M45l7xKDeiqmgeMAuYCK4CZqrpcRMaJyIBAsrlAjoh8\nCcwH/p+q5sQjwy1awIUXwrPPws8/x+MMzjmXnJJykeh//hN+9SvIzITLLotxxpxzrgJLuUWi+/WD\nY46Ba66BKlUgLc2Cu3POVWZJucDF9OmQkwP799v2hg0wYoQ9HzYscflyzrlESsoS+tixBcE8aM8e\n2++cc5VVUgb0jRuj2++cc5VBUgb0Fi2i2++cc5VBUgb08eOhdu3C+2rXtv3OOVdZJWVAHzbMBhYF\nS+T169u2N4g65yqzpAzoYMF7wwbrsnjeeR7MnXMuaQN6UOvWsGpVonPhnHOJl/QBvU0bC+gJGvDq\nnHMVRtIH9NatITcXduxIdE6ccy6xUiKgg1e7OOdcygT0r79ObD6ccy7Rkj6gp6VBtWpeQnfOuaQP\n6NWrQ6tWHtCdcy7pAzp410XnnIMUC+jeddE5Fyu7d8O2bYnORXQiCugi0l9EVorIahEZE+b1q0Rk\nu4gsCTyui31Wi9e6Nfz4I2zdWp5ndc6lstGj4Ze/THQuolNqQBeRqsAk4FwgHRgqIulhkr6sqp0C\nj2djnM8StWljP73axTkXKx9/DGvXJlcpPZISejdgtaquVdV9wAxgYHyzFR3vi+6ci6WffoIVK+z5\nkiWJzUs0IgnoTYFNIdvZgX1FXSwiS0XkFRFpHpPcRah5c6hRwwO6cy42vvwS8vLseaoF9Ei8BaSp\nakfgPeDv4RKJyAgRyRKRrO3bt8fo1FC1Kpxwgg8ucs7FRjCI16qVegF9MxBa4m4W2HeQquao6s+B\nzWeBruEOpKqTVTVDVTOaNGlyOPktlndddM7Fyn//C3Xrwtln2/NkEUlAXwi0FpFWIlIDGALMCk0g\nIseGbA4AVsQui5Fp0wbWrIH8/PI+s3Mu1SxZAqecAl272jf/H39MdI4iU2pAV9U8YBQwFwvUM1V1\nuYiME5EBgWS3ishyEfkcuBW4Kl4ZDiczE6ZMsYaMFi1s2znnDkd+Pnz+OXTqZA9VWLYs0bmKTLVI\nEqnqHGBOkX33hjy/C7grtlmLTGYmjBgBe/bY9ubNtg2+ipFzLnrr1sEPPxQEdLBql+7dE5uvSCT9\nSNGxYwuCedCePbbfOeeiFawz79zZvvE3bJg8DaNJH9A3boxuv3POlWTJEus51749iFgp3QN6OWnR\nIrr9zjlXkiVLoF0767IIFtCXLi3olx6JTz6Bjh1h+fL45LE4SR/Qx4+H2rUP3X9duc4m45xLFUuW\nWHVLUOfO1uEi0nEu330HQ4ZYQ+rEifHJY3GSPqAPGwaTJ0PLlvb1qHlz+2T1QUbOuUgcOFDQ3Xn7\ndutYEWwMhYLnkVS7qFphcssWOOssmD7dAnx5SfqADhbU16+3m7Jxo/VymTHDZ190zpXsk0+seqV9\ne1i4sCBohwb0tm1tapFgY2lOjqULN13300/Da6/B//wPPPII7N0LL7wQ/+sISomAXtSoUbB/P0yd\nmuicOOcqon37rCfcGWfY89274fTT4e677fXQgF69Opx8MsybBzfcYLUAnTvDr34FX3xhabZvt+qV\n22+3/XfeaWlOOw2eeqr81mpIyYDeujX06QPPPOMjR51zhf38M/Tta6Xoq66yBs9ly+ybflaWdaho\n1Kjwezp3hsWLrbQ9bBg89JClPeUU6NULmja1IJ6RAX//O1QJRNaRI+Grr+D998vp4lQ1IY+uXbtq\nPM2YoQqqc+fG9TTOuSRzww0WG1544dDX5sxRfe+9Q/evWqX6t7+pbt9esG/HDtVbblE98UTV229X\n/eKLQ9+3Z49qw4aql1xSsC83V/WHHw4//0CWFhNXRRO0bltGRoZmZWXF7fg//wzNmkHPnvDKK3E7\njXMuiUydCtdcA7/7nZWyy8Odd8Jjj8Gvf21176tXw7PPwrXXHt7xRGSRqmaEey0lq1wAata0r1Nv\nvgnffJPo3DjnEm3xYqsC6dPHujuXl5tusq7VixdbFc2f/gTdusXnXCkb0AGuv94GAzz/fKJz4pwr\nq5wcuP9++xmt+fPhggugSRPrSlgtolmsYuOEE2DXLpsN9pVXrDG2Q4f4nCulA3qbNlbl4o2jziW/\nu+6C++6D88+PfDrb/fut50rfvlCvHsyZA7/4RVyzGZZI+ZwnpQM6WJ/0tWvtE9o5l5yWLoXnnrPB\nOgsXwqWXWrAuyc6dVqD785+tvnrx4viVjCuKlA/oF11kK4+8/HKic+Kci8TGjfCXv9igHLA+3Hfe\nCfXrw+uvwxNPWEn7uuuKn18lJ8dK5YsW2SDDZ56BOnXK7xoSJeUDeq1acOGF9ocQzeQ6zrnypwpX\nXAGjR8Mvf2lzk7/zDvzrX/DHP1r/8BtusLr0F16AtDR7vmVLwTF27LBgvmKFdYr4zW8SdjnlLmW7\nLYZ67TW4+GJ47z3o169cTumcOwzTp8Nll1kVyauvWt1z/fo2WvOLL2wIPljgf/ttmDQJ5s61dI0a\n2dzlu3dbI+Sbb8I55yT2euKhpG6LlSKg791rrdvDhtlcC8652MjJgQYNbP7wsvrhBzjpJDjuOFiw\nwOZnGjTIRnG+/rr14w5nzRr7INiyxSbC2rPHhuD36lX2PFVEZQ7oItIfeBSoCjyrqg8Wk+5i4BXg\nVFUtMVqXZ0AHm85y3jy76eXZZcm5VLVokTVSXnutDZwJpRp9z47Ro63u/NNPbQ4UsOD83/9a9Ut5\n9RSp6Mo0sEhEqgKTgHOBdGCoiKSHSVcPuA1YULbsll1mptWtValiPzMz4ZJLbAKdDz5IdO6cS36b\nN8OAARZwn33WepQEqVoddno6TJtW0Ha1c6eN1Bwxwqo+W7WCY4+1gT4jR8Kjj1pDZzCYgw3I6dHD\ng3mkImkU7QasVtW1qroPmAEMDJPuAeAh4KcY5i9qwUWjN2ywP6wNG2w7N9f+OP7xj0Tmzrnk9+OP\nFsy//94C9t691qUw6K23rJtwbi4MH27T055zDhx9tA27f+01q+f+5S+hf3873rRp0LixdTF0h6/U\nKhcRGQz0V9XrAtvDgdNUdVRImi7AWFW9WETeB0aHq3IRkRHACIAWLVp03bBhQ8wuJCgtzYJ4US1b\n2nDb//zHql1iUefnXGXz009WffnWWzBrlg3y6d3bxnqsWWPfijt3tiC/fDnMnm1BOjfX6sMHD4Yu\nXQ4tcataSb569cRcVzKJ61wuIlIFmAjcWVpaVZ2sqhmqmtGkSZOynjqskhaNvuQS+PZbr3ZxrjQ5\nOXD55TYVbHAAz5o1Vqp+801bvOH8823/bbfZ/9esWfYNeOlS60pYvbo1ZC5YYFPI/vnP0LVr+OoT\nEQ/msRBJCf104D5V/VVg+y4AVf1zYLs+sAbYHXjLMcBOYEBJDaPxahQtqYS+fLm1oF94oX3Fc86F\nd+WVBSvttGplXQkff9y+2b7wgs2LEnTgAJx4os1uun27BebPPy+YE9zFVllL6AuB1iLSSkRqAEOA\nWcEXVTVXVY9S1TRVTQM+pZRgHk/hFo2uXdv216ljMzD+4x+wbVsicudcyfLz7Zvk228nLg/vvWdB\n++67rdR91FH2/3PSSTZ8PjSYgwX5UaPgo49g5UoYN86DecIUN1F66AM4D/gaK4mPDewbhwXuomnf\nBzJKO2Y8F7iYNk21ZUtVEfs5bVrBa199ZZPb/+lPcTu9c4ft88/t7/PMM0tO9+OPqtnZqj//HP05\nNm1Svf9+1TVrwh+3VSvVNm1U9+61ffn5qkuWlHyunTtVa9dW7dLF0rv4oYQFLlJ2xaKSnH22arNm\nqvv3JywLzoX1l7/YfyWobtgQPk1+vuqppxakO/JI1eHDVfPySj9+fr5q//72vipVVC+7TDUry1bR\nyc9XHT3aXnv//ejz/sknqmvXRv8+F52SAnql/GJ0882QnW1fJ52rSP79b6vigOInlHvrLZtx8Oab\n4YEHrAvhiy9aVUdQfj7ceqstqPDttwX7Z8+Gd9+16pTbb7cGzoyMguH1EyZYX/CePaPPe/fuVt/u\nEqdSDP0v6sABOP54m3h+3ryEZMG5Q+zfb3ORXHmlBey8PKuzDqVqAXjXLquvrlbN9l1zjS3k8tZb\ncN55trjLlClWv33aafZBIQLt2xc0WtaoYYN93nrLJrTaudOOd8cdFuBdxVRSo2ilHARftaqNTLvr\nLpsD4sQTbWKfVq28McclzoIFNsimb1/7m7zjDgvaJ51UkGb2bAvyzz1XMIWFiE0pu3SpdTXs188m\ntrr3Xpv/+5JLLMC3b29dD999t2CSq0aN7APEpYji6mLi/UhkHbqqrd5dp05BPSSojh2b0Cy5Su6+\n+6whf+dO1c2b7fkf/1jwen6+akaGNVru23fo+9etU23UyP6W77+/YP8DDxTUmQ8YEO+rcPFGCXXo\nlbLKJWjLFptveedO65b13XdWInIuEc4800ZiLlxo23362JwpX31lpfA5c2wwzzPPWD13OIsWwapV\nNpozSNWG4L/xhlW1nHBC/K/FxY9XuRTjuOPsATbSbdQo+PprW4vUuaC33rLAeuON8TvH7t02y+Do\n0QX7hg61eYgmT7bFGmbMsNhVlK4AABXUSURBVAFyV1xR/HG6drVHKBFrNM3NtaluXeryGuOA4DDm\n2bMTmw9Xsaja0Pbf/tYCYqzs2gW33ALBL6kffmiNoH37FqS5+GJrwLzxRnjqKZsDZfr0gvrvaIh4\nMK8MUj6gh5tKN5y0NGs0SuQIPVfxfPKJVcv9/LN18YuFAwes9P23v8EZZ9g0FP/6F9SsaVPFBjVq\nZF1r33jD5laZMwdOPz02eXCpKaWrXIJT6e7ZY9vBqXTBVi8q6oILbIL93FzvtuXMtGm2Lm3jxtYv\nvKTqjkj97nfW0+ShhyxIDx9u01L06AFHHFE4bf/+ZT+fqzxSuoQ+dmxBMA/as8f2h3PBBfa195//\njH/eXMW3bx/MnGkzBl52mf1dhC7ksG6dBfxo+hVMmQITJ1p1y+9+Z/Om3HSTdVf04O3KKqUDeklT\n6YbTvbt9zY1VtYuqrZPoktPcuQXTyA4ZYh/2r71mr+3fb/N7Dx9uU8mG2rrVFi/etatgn6qt7HPj\njdZPfOJE21+9uqVdtMjq6Z0ri5QO6C1aRLe/WjU491z7GnzggPVsGDwY/vCHwzv/5Mm2xFZoqc4l\nj2nTbBj+OefYog0nnlgwHH/iROsC2LGj9Ux55x3bv2yZLaQyapT1lnrmGbv/Q4bY4J6zzrJSf9F1\nbbt08fnAXQwU10E93o/yGFg0bZrNABc6eKh27cKzLxY1fbqlu+su1YYN7bmIzYIXjQMHVFu3tve/\n+27ZrsOVv127VGvVUh01qmDfPffY4JyPP7bXBg1S3b1btVMn1Xr1VJ94wn4ed5z9HZ1xht3/GjVU\nq1VTffBB+7twriyozLMtljSVbjg7d6pWrWq/mW7dVBcssNF355wT3Xnnzi34EPGpepPPlCl27z79\ntGDfsmV6cHbDI4+06WtVVTduVD36aHutQwfbVrWRnTNmqJ5/vs1E6FwsVOqAfjjGj7fSVHB63Uce\nsd/UO+9EfowLL7R/8rQ0K8m5+Pj+exsev2tX7I65ebPNB37iiYfO7d2+vf0tPPFE4f2LF9vUs7m5\nscuHc+GUFNAr9dD/SO3bB+np1n1tyZJD6z+LWrfOhlePHQurV8PHH4dfFs+V3WOP2cCfm26yxsWy\n2rDBBvds22aDzM46q/DrL71kPVOee84ncnOJEddFoiuDGjWsz/Dy5TB1aunpn3zS/tlvuMGGYW/c\naGstutgLDhR78knrKVKSbdusl8rYsbZcWlGrV9t8Kjk5FrSLBnOw7otTp3owdxVTRH+WItJfRFaK\nyGoRGRPm9RtFZJmILBGRj0QkPfZZTayLLrJRfaNH27waxdm710pvv/61LZobnFejtGDjord6NXz2\nGdxzDxx9tE2JfODAoekWLYJOneCYY2w4/f/8D/TqZaX7YEvHiy/Cqafa/Zs3z7qwOpdsSg3oIlIV\nmAScC6QDQ8ME7JdUtYOqdgIeBibGPKcJJmKlwSOOsAFIO3aET/fcc9ZNbdQo2+7SxX4mSe1SUnnp\nJbsvN9xgI3wXLrRugkGqFrRPP91K3Q8/bEP5d+ywe3jbbXD11fbhe8UVNvXDJ59YF0XnklJxlevB\nB3A6MDdk+y7grhLSDwXeKe24FblRtCSffKJas6bqWWcdumhuVpa91rdv4ca01q1Vf/3r8s1nqsvP\nt4bLXr0Ktnv3Vm3QQPXWW1VHjlTt08fK3xdcoLpjR+H3Hzigeu+99nqtWraWZyRrcjqXaJSllwsw\nGHg2ZHs48Lcw6W4G1gCbgNbFHGsEkAVktWjRotx+AbEW7Ks+eLAtlKFqP1u0sMe33xZOP2SIavPm\n5Z/PVJaVZfdg8uSCfStWqB5/vGr9+qqNG9vvfOLEkleh/+gj1VWr4p9f52KlpIAes6YdVZ2kqicA\nvwfuKSbNZFXNUNWMJk2axOrUEYt05sXSDBliX99ff91GD06YYPuCjW5FLy0jAzZtKrxYbzLat89G\nzb70ks3fnUiZmTaycvDggn1t29oSa7t2WbXKxo22ELJI8cfp0cPuoXMpobhIrwWl6mirXKoAuaUd\nt7yrXA5n1GhpvvxS9bzzCo43dWr4dPPn2+tz5hz+uSqCzMyCaz3iCNVLL7Vlz0qSl1f20ZGLFqle\ndpkNDLv+etV//lP12GNVBw4s23GdS0aUscqlGrAWaAXUAD4H2hdJ0zrk+YUlnTD4KO+A3rJl4WAe\nfLRsWfZjv/ee6vPPF/96bq6d64EHyn6uROrTx9az/M9/VG+6yYa5t22r+t134dN/8olqs2aqF198\naLVHfr4Nmy8qN9eqQaZNsxG2vXrZ765ePRtxWbduwb2bOTP21+hcRVemgG7v5zzga6yOfGxg3zhg\nQOD5o8ByYAkwv2jAD/co74AuEj6gi5TP+du0ib5EuWlTxWmoW7Pm0A+l99+3OUp+9auCUbWqFqyf\neEK1enWrzy5a1/399zatgojqySerXnut6i23qHbubHOlhN6fVq1UJ0woGAm6Z4/qa6+pjht3aKO0\nc5VBmQN6PB6pVEKPxNChVlqN1Lp1NqnT5ZdH/p6dO1VzcqLOWkTGjrVgu2lT4f3PPGO/x9tuU922\nzRqMBw2yfeeea71L+vZVrVPHGh9//tnmxalaVfW3v7U0DRtaFU6fPjaMf/Zsq8768cf4XItzycwD\nusanDj0af/mLnXP16sjS//73Bfl88cXS0//0k3WPbNNGdd++suW1qLw81aZNrb0gnNtuK/x7rV9f\n9b77CurON22y7oTdu6sOH25ppkwpeH9+fsX5JuJcRecBPSDamRdjae1aqwfOyFDdu7fktHv2WLe7\ngQNtCtZ69azKoyQPPlgQUJ98MrI85eVZvkr7AJg924776qvhX9+/X/Xuu21Ss88+Cx+cg109U6Et\nwblEKimg++Rc5ejNN21U4lVX2VJkwe50u3YVXpH9+edtBOO8eXD88XDKKdYl78MPwy+CsHWrLabQ\np4+NUl292h516hSfl2+/hd/8Bt5/347Zpg106ACnnWYjKzt3Llhd/uKL7dzZ2Ye34nzQ3Xfbue67\nr+SuhM654pU0OVelKqFXBH/4g5VSH35Y9amnVE87rXCpNT9ftWtX1fT0gp4hL79saW6+OfwgmSuu\nsPr21atV/+//LO348QWv//ST6oYNBSXnhQtt0E2tWnbeMWNsut/mzQtK0dWqWZ1/RoY9Hz06vr8X\n51xk8CqXQyWq+uXAgcJ919u3t0bCYJD/9FMNO9/2nXfa/t//vnBQD6YfM6Zg34ABtgDDN99Y75Km\nTS1N9epWx16zpo1ozco6NH/Z2ar/+Iet2HTlldaD5YwzSu9v7pwrHyUF9EpZ5ZKZCSNGwJ49Bftq\n17Y1QIcNi//5c3PhqaesiiQjw2YIvPxyW6/yhBNsqt3Nm6Fu3YL3qNqc3089BePGWZXMlCm2DbBy\nJdSrZ8+XL7e1Lo84wlaT797djp+dbVUxtWvb6NYEDNZ1zpWRV7kUkegujOHs22cTeIH1yQ7nwAGr\nXgn2nwfVs88uvExa0J13WtXNm2+WPJeJcy654CX0wqpUsRBelAjk55d/foJ+/tmm3/3Nb6Bx4/Bp\n8vJsgYYaNeCaa6BVq/LNo3MusUoqoZeymFpqatEi/JJwLVqUf15C1axp1SolqVbNVk9yzrmiKuVC\nWuPHWz1yqNq1bb9zziWrShnQhw2zBtCWLa2apWXL8msQdc65eKmUVS5gwdsDuHMulVTKErpzzqUi\nD+jOOZciPKA751yK8IDunHMpwgM6sVs82jnnEqnS9nIJKjqvy4YNtg3eC8Y5l1wiKqGLSH8RWSki\nq0VkTJjX7xCRL0VkqYj8W0Raxj6r8TF2bOFJusC2x45NTH6cc+5wlRrQRaQqMAk4F0gHhopIepFk\n/wUyVLUj8ArwcKwzGi8bN0a33znnKqpISujdgNWqulZV9wEzgIGhCVR1vqoGy7mfAs1im834KW7+\nlkTP6+Kcc9GKJKA3BTaFbGcH9hXnWuCdcC+IyAgRyRKRrO3bt0eeyzjyeV2cc6kipr1cRORyIAP4\n33Cvq+pkVc1Q1YwmFWR1haLzujRubAtDDB/uPV6cc8klkoC+GWgest0ssK8QEekHjAUGqOrPscle\n+Rg2DNavhxdfhL17ISfH5ksP9njxoO6cSwaRBPSFQGsRaSUiNYAhwKzQBCLSGXgaC+bfxj6b5cN7\nvDjnklmpAV1V84BRwFxgBTBTVZeLyDgRGRBI9r9AXeAfIrJERGYVc7gKzXu8OOeSWUQDi1R1DjCn\nyL57Q573i3G+EqKirmTknHOR8KH/IbzHi3MumXlAD+ErGTnnkpkH9CKCPV7y861kPnasT9rlnEsO\nlX5yruL4pF3OuWTjJfRieBdG51yy8YBeDO/C6JxLNh7Qi1FcV0VVr093zlVMHtCLEa4LY5BPCeCc\nq4g8oBcjtAtjOF6f7pyraDyglyDYhVEk/Oten+6cq0g8oEfAF8FwziUDD+gRCFefLmJ16d5A6pyr\nKDygR6BofbqI9XYBbyB1zlUcHtAjFKxPb9myIJgHeQOpc64i8IAeJR9w5JyrqDygR8kbSJ1zFZUH\n9Ch5A6lzrqKKKKCLSH8RWSkiq0VkTJjXzxKRxSKSJyKDY5/NisMbSJ1zFVWpAV1EqgKTgHOBdGCo\niKQXSbYRuAp4KdYZrIi8gdQ5VxFFMh96N2C1qq4FEJEZwEDgy2ACVV0feC0/DnmssLyB1DlXkURS\n5dIU2BSynR3YFzURGSEiWSKStX379sM5RIXiMzI65yqScm0UVdXJqpqhqhlNmjQpz1PHhc/I6Jyr\nSCIJ6JuB5iHbzQL7Kj2fkdE5V5FEEtAXAq1FpJWI1ACGALPim63kUdqMjN6d0TlXXkoN6KqaB4wC\n5gIrgJmqulxExonIAAAROVVEsoFLgKdFZHk8M10RlTSwyKtfnHPlQbRov7tykpGRoVlZWQk5dzxk\nZlrQLrqwdFEtW1rd+7Bh5ZMv51xqEZFFqpoR7jUfKRojpdWnB3lp3TkXLx7QYyh0wFFJvLHUORcP\nHtDjoKTujEHBxtKbbrKfVap446lzrmwiGSnqohSsHx871gJ3cTZsgCefLLw9YkThYzjnXKS8hB4n\nweqXadNKL62H8uoY59zh8oAeZ5E2lobyuWCcc4fDA3o5iLSxNMjngnHOHQ4P6OUoksbSoA0bYPhw\nG4Hqwd05FwkP6OUotPpFxH6OHFl8yT104QwP7s650vhI0QqiSpVDF8soTnCVJB916lzl4yNFk0A0\ni0x7yd05F44H9Aoimvr1UB7cnXNBHtAriHCLT0fLg7tzlZsH9Aok2L1RFV58MfbB/aij7OHTDDiX\nmjygV1DxCO45OfZQLT7Qe9B3Lnl5QE8CsQzuocIF+qJB/+qrPdg7lyw8oCeZeAX34uzfX3ywL62E\nH+1z/5Bwrmw8oCex8g7uRZVWwo/2eVk+JIpORVyeHyaZmT4FsqsgVLXUB9AfWAmsBsaEeb0m8HLg\n9QVAWmnH7Nq1q7r4mDZNtWVLVVAVsZ/+KP0R/F01bmwPkdKfh/sdhztOy5aqI0faz0iOm8jnFT2v\nqZK/li3tfzVaQJYWF6uLe+FgAqgKrAGOB2oAnwPpRdLcBDwVeD4EeLm043pALx/B4F5aEPKHP/xR\n/o/ataMP6iUF9EiqXLoBq1V1raruA2YAA4ukGQj8PfD8FaCvSHl98XclCVbL5OfDjh32UC2oohGB\nxo3tEe55jRqJvgLnUles1z+IJKA3BTaFbGcH9oVNo6p5QC7QuOiBRGSEiGSJSNb27dsPL8cuJsIF\n+nDPp0w5NPBD+dXTO5fqYrn+Qbk2iqrqZFXNUNWMJk2alOep3WEqawk/0ufgHxKucopmHqfSRLKm\n6Gagech2s8C+cGmyRaQaUB/IiUkOXYU0bFjsZ3nMzLSvnxs3QqNGtm/nzsiet2gB550Hc+ZE//6c\nnIIZLA9X8P1lPY6rXGrXtnmcYqa4yvXgAwv6a4FWFDSKti+S5mYKN4rOLO243ijqKpJwjcfR9GoI\nNmwVd5yK3jMjmfKaKvmLRy+XiOZDF5HzgEewHi9TVHW8iIwLHHiWiNQCXgQ6AzuBIaq6tqRj+nzo\nzjkXvZLmQ4+kygVVnQPMKbLv3pDnPwGXlCWTzjnnysZHijrnXIrwgO6ccynCA7pzzqUID+jOOZci\nIurlEpcTi2wHNkTxlqOAHXHKTkVWGa+7Ml4zVM7rrozXDGW77paqGnZkZsICerREJKu4rjqprDJe\nd2W8Zqic110Zrxnid91e5eKccynCA7pzzqWIZArokxOdgQSpjNddGa8ZKud1V8Zrhjhdd9LUoTvn\nnCtZMpXQnXPOlcADunPOpYikCOgi0l9EVorIahEZk+j8xIOINBeR+SLypYgsF5HbAvsbich7IrIq\n8LNhovMaayJSVUT+KyJvB7ZbiciCwP1+WURSbiE8EWkgIq+IyFciskJETq8k9/r2wN/3FyIyXURq\npdr9FpEpIvKtiHwRsi/svRXzWODal4pIl7Kcu8IHdBGpCkwCzgXSgaEikp7YXMVFHnCnqqYD3YGb\nA9c5Bvi3qrYG/h3YTjW3AStCth8C/qqqJwLfAdcmJFfx9Sjwrqq2BU7Brj+l77WINAVuBTJU9WRs\nOu4hpN79fh7oX2Rfcff2XKB14DECeLIsJ67wAZ3IFqlOeqq6VVUXB57/gP2DN6XwAtx/B36dmBzG\nh4g0A84Hng1sC9AHW2wcUvOa6wNnAc8BqOo+Vd1Fit/rgGrAEYGVzWoDW0mx+62qH2DrQoQq7t4O\nBF4IrF3xKdBARI493HMnQ0CPZJHqlCIiadhiIQuAo1V1a+Clb4CjE5SteHkE+B2QH9huDOxSW2wc\nUvN+twK2A1MDVU3PikgdUvxeq+pmYAKwEQvkucAiUv9+Q/H3NqbxLRkCeqUiInWBV4Hfqur3oa8F\nlp9KmX6mInIB8K2qLkp0XspZNaAL8KSqdgZ+pEj1Sqrda4BAvfFA7APtOKAOh1ZNpLx43ttkCOiR\nLFKdEkSkOhbMM1X1tcDubcGvYIGf3yYqf3HQAxggIuuxqrQ+WN1yg8BXckjN+50NZKvqgsD2K1iA\nT+V7DdAPWKeq21V1P/Aa9jeQ6vcbir+3MY1vyRDQFwKtAy3hNbBGlFkJzlPMBeqOnwNWqOrEkJdm\nAVcGnl8JvFneeYsXVb1LVZupahp2X+ep6jBgPjA4kCylrhlAVb8BNonISYFdfYEvSeF7HbAR6C4i\ntQN/78HrTun7HVDcvZ0FXBHo7dIdyA2pmolecatHV6QHcB7wNbAGGJvo/MTpGs/AvoYtBZYEHudh\ndcr/BlYB/wIaJTqvcbr+XsDbgefHA58Bq4F/ADUTnb84XG8nICtwv98AGlaGew3cD3wFfIEtLF8z\n1e43MB1rI9iPfRu7trh7CwjWi28NsAzrAXTY5/ah/845lyKSocrFOedcBDygO+dcivCA7pxzKcID\nunPOpQgP6M45lyI8oDvnXIrwgO6ccyni/wN82fzyY7V8KAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjWWMw04sh8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5-3mqokcL3E",
        "colab_type": "code",
        "outputId": "224918ad-be2c-44e7-d937-3a9808b08f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               4718848   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 26,521,889\n",
            "Trainable params: 26,487,457\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r53fwHtdcON9",
        "colab_type": "code",
        "outputId": "edd3e0df-6fda-407f-e209-a5ed5b12b2a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=360,\n",
        "  # width_shift_range=0.2,\n",
        "  # height_shift_range=0.2,\n",
        "  # shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=20,\n",
        "  class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "  validation_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=20,\n",
        "  class_mode='binary')\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "  optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "  metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100,\n",
        "  epochs=30,\n",
        "  validation_data=validation_generator,\n",
        "  validation_steps=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2597 images belonging to 2 classes.\n",
            "Found 1558 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "100/100 [==============================] - 52s 519ms/step - loss: 0.7269 - acc: 0.5379 - val_loss: 0.6248 - val_acc: 0.6850\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 35s 351ms/step - loss: 0.6432 - acc: 0.6473 - val_loss: 0.5452 - val_acc: 0.7300\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 0.5881 - acc: 0.6947 - val_loss: 0.5869 - val_acc: 0.7150\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 0.5239 - acc: 0.7370 - val_loss: 0.5268 - val_acc: 0.7450\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.4761 - acc: 0.7832 - val_loss: 0.3127 - val_acc: 0.8600\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.4169 - acc: 0.8025 - val_loss: 0.3682 - val_acc: 0.8250\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.3398 - acc: 0.8514 - val_loss: 0.3018 - val_acc: 0.8850\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.3045 - acc: 0.8711 - val_loss: 0.2063 - val_acc: 0.9141\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 0.2347 - acc: 0.9079 - val_loss: 0.2104 - val_acc: 0.9200\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.2224 - acc: 0.9085 - val_loss: 0.2775 - val_acc: 0.8900\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 0.1910 - acc: 0.9215 - val_loss: 0.0851 - val_acc: 0.9700\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 0.1740 - acc: 0.9349 - val_loss: 0.0359 - val_acc: 0.9850\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.1498 - acc: 0.9395 - val_loss: 0.0758 - val_acc: 0.9700\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.1544 - acc: 0.9378 - val_loss: 0.1213 - val_acc: 0.9650\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.1076 - acc: 0.9630 - val_loss: 0.1263 - val_acc: 0.9650\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 0.0878 - acc: 0.9693 - val_loss: 0.0529 - val_acc: 0.9848\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 0.0997 - acc: 0.9639 - val_loss: 0.1079 - val_acc: 0.9600\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.1058 - acc: 0.9609 - val_loss: 0.0125 - val_acc: 0.9950\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.1058 - acc: 0.9600 - val_loss: 0.0510 - val_acc: 0.9800\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.0906 - acc: 0.9674 - val_loss: 0.0418 - val_acc: 0.9950\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.0701 - acc: 0.9750 - val_loss: 0.0767 - val_acc: 0.9850\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 0.0699 - acc: 0.9780 - val_loss: 0.0583 - val_acc: 0.9800\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 0.0771 - acc: 0.9740 - val_loss: 0.0544 - val_acc: 0.9750\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 38s 376ms/step - loss: 0.0699 - acc: 0.9735 - val_loss: 0.0186 - val_acc: 0.9949\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 0.0519 - acc: 0.9780 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.0453 - acc: 0.9819 - val_loss: 0.0718 - val_acc: 0.9900\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 0.0684 - acc: 0.9745 - val_loss: 0.0511 - val_acc: 0.9900\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 0.0481 - acc: 0.9815 - val_loss: 0.0061 - val_acc: 1.0000\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 0.0474 - acc: 0.9840 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.0524 - acc: 0.9835 - val_loss: 0.0136 - val_acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7--W__dKxgY",
        "colab_type": "code",
        "outputId": "1b78f097-9d31-4b54-b482-123241d5ee53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neZKG+W0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU1fnA8e/LLvuqyBpcWcMWsRaV\nRatYFYoCgsGKiiwV0aIWCoqI8hOUImqpFXcFQdSqKChuVLRVJFAEERGEqFFECIsgIIS8vz/OJEzC\nTHInuZPJTN7P88yTuXfOPffcTPLOmXPOPUdUFWOMMfGvXKwLYIwxxh8W0I0xJkFYQDfGmARhAd0Y\nYxKEBXRjjEkQFtCNMSZBWEA3IYlIeRHZJyLN/EwbSyJyioj4Pk5XRM4XkfSg7Q0ico6XtEU41+Mi\nMr6oxxeQ7z0i8rTf+ZqSVSHWBTD+EJF9QZtVgV+BI4Ht4ao6N5L8VPUIUN3vtGWBqp7uRz4iMhQY\nrKrdg/Ie6kfeJjFZQE8QqpobUAM1wKGq+m649CJSQVWzSqJsxpiSYU0uZUTgK/ULIjJPRPYCg0Xk\nLBH5RER2i8hWEXlIRCoG0lcQERWRpMD2nMDrb4rIXhH5WERaRJo28PpFIvKViOwRkYdF5D8iMiRM\nub2UcbiIbBKRXSLyUNCx5UXkARHJFJHNQK8Cfj8TRGR+vn2zRGRG4PlQEVkfuJ6vA7XncHlliEj3\nwPOqIvJcoGzrgM750t4uIpsD+a4Tkd6B/e2AvwPnBJqzdgT9bicFHT8icO2ZIvKqiJzo5XdTGBHp\nGyjPbhF5X0ROD3ptvIj8ICI/i8iXQdf6GxFZFdi/TUTu93o+4xNVtUeCPYB04Px8++4BDgGX4j7I\njwPOAM7EfVM7CfgKGBVIXwFQICmwPQfYAaQAFYEXgDlFSHs8sBfoE3htDHAYGBLmWryU8TWgFpAE\n7My5dmAUsA5oAtQDlrk/+ZDnOQnYB1QLyvsnICWwfWkgjQA9gQNAcuC184H0oLwygO6B59OBfwN1\ngObAF/nSDgBODLwnVwbKcELgtaHAv/OVcw4wKfD8gkAZOwBVgH8A73v53YS4/nuApwPPWwXK0TPw\nHo0HNgSetwG+ARoG0rYATgo8XwEMCjyvAZwZ6/+FsvawGnrZ8pGqvq6q2ap6QFVXqOpyVc1S1c3A\nbKBbAce/pKppqnoYmIsLJJGmvQRYraqvBV57ABf8Q/JYxntVdY+qpuOCZ865BgAPqGqGqmYCUws4\nz2bgc9wHDcDvgF2qmhZ4/XVV3azO+8B7QMiOz3wGAPeo6i5V/QZX6w4+7wJV3Rp4T57HfRineMgX\nIBV4XFVXq+pBYBzQTUSaBKUJ97spyEBgoaq+H3iPpuI+FM4EsnAfHm0CzXZbAr87cB/Mp4pIPVXd\nq6rLPV6H8YkF9LLlu+ANEWkpIotE5EcR+RmYDNQv4Pgfg57vp+CO0HBpGwWXQ1UVV6MNyWMZPZ0L\nV7MsyPPAoMDzKwPbOeW4RESWi8hOEdmNqx0X9LvKcWJBZRCRISLyWaBpYzfQ0mO+4K4vNz9V/RnY\nBTQOShPJexYu32zce9RYVTcAt+Deh58CTXgNA0mvAVoDG0TkUxH5vcfrMD6xgF625B+y9yiuVnqK\nqtYEJuKaFKJpK64JBAAREfIGoPyKU8atQNOg7cKGVS4AzheRxria+vOBMh4HvATci2sOqQ287bEc\nP4Yrg4icBDwCjATqBfL9MijfwoZY/oBrxsnJrwauaed7D+WKJN9yuPfsewBVnaOqXXHNLeVxvxdU\ndYOqDsQ1q/0NeFlEqhSzLCYCFtDLthrAHuAXEWkFDC+Bc74BdBKRS0WkAnAT0CBKZVwA3CwijUWk\nHjC2oMSq+iPwEfA0sEFVNwZeqgxUArYDR0TkEuC8CMowXkRqixunPyroteq4oL0d99l2Pa6GnmMb\n0CSnEziEecB1IpIsIpVxgfVDVQ37jSeCMvcWke6Bc9+G6/dYLiKtRKRH4HwHAo9s3AVcJSL1AzX6\nPYFryy5mWUwELKCXbbcAV+P+WR/FdV5GlapuA64AZgCZwMnA/3Dj5v0u4yO4tu61uA67lzwc8zyu\nkzO3uUVVdwN/Bl7BdSz2w30weXEn7ptCOvAm8GxQvmuAh4FPA2lOB4Lbnd8BNgLbRCS46STn+Ldw\nTR+vBI5vhmtXLxZVXYf7nT+C+7DpBfQOtKdXBu7D9Xv8iPtGMCFw6O+B9eJGUU0HrlDVQ8Utj/FO\nXBOmMbEhIuVxX/H7qeqHsS6PMfHMauimxIlIr0ATRGXgDtzoiE9jXCxj4p4FdBMLZwObcV/nLwT6\nqmq4JhdjjEfW5GKMMQnCaujGGJMgYjY5V/369TUpKSlWpzfGmLi0cuXKHaoacqhvzAJ6UlISaWlp\nsTq9McbEJREJe8ezNbkYY0yCsIBujDEJwgK6McYkCFuxyJgy4vDhw2RkZHDw4MFYF8V4UKVKFZo0\naULFiuGm8jmWBXRjyoiMjAxq1KhBUlISbpJLU1qpKpmZmWRkZNCiRYvCDwiIqyaXuXMhKQnKlXM/\n50a07LExZdvBgwepV6+eBfM4ICLUq1cv4m9TcVNDnzsXhg2D/fvd9jffuG2A1GLPL2dM2WDBPH4U\n5b2Kmxr6hAlHg3mO/fvdfmOMMXEU0L/9NrL9xpjSJTMzkw4dOtChQwcaNmxI48aNc7cPHfI2bfo1\n11zDhg0bCkwza9Ys5vrUHnv22WezevVqX/IqCXHT5NKsmWtmCbXfGOO/uXPdN+Bvv3X/Z1OmFK95\ns169ernBcdKkSVSvXp1bb701T5rc1evLha5rPvXUU4We54Ybbih6IeNc3NTQp0yBqlXz7qta1e03\nxvgrp8/qm29A9WifVTQGImzatInWrVuTmppKmzZt2Lp1K8OGDSMlJYU2bdowefLk3LQ5NeasrCxq\n167NuHHjaN++PWeddRY//fQTALfffjszZ87MTT9u3Di6dOnC6aefzn//+18AfvnlFy6//HJat25N\nv379SElJKbQmPmfOHNq1a0fbtm0ZP348AFlZWVx11VW5+x966CEAHnjgAVq3bk1ycjKDBw/2/XcW\nTtzU0HNqBn7WGIwxoRXUZxWN/7kvv/ySZ599lpSUFACmTp1K3bp1ycrKokePHvTr14/WrVvnOWbP\nnj1069aNqVOnMmbMGJ588knGjRt3TN6qyqeffsrChQuZPHkyb731Fg8//DANGzbk5Zdf5rPPPqNT\np04Fli8jI4Pbb7+dtLQ0atWqxfnnn88bb7xBgwYN2LFjB2vXrgVg9+7dANx333188803VKpUKXdf\nSfBUQw+sMLNBRDaJyDG/MRF5QERWBx5fiUhUriA1FdLTITvb/bRgbkx0lHSf1cknn5wbzAHmzZtH\np06d6NSpE+vXr+eLL7445pjjjjuOiy66CIDOnTuTnp4eMu/LLrvsmDQfffQRAwcOBKB9+/a0adOm\nwPItX76cnj17Ur9+fSpWrMiVV17JsmXLOOWUU9iwYQOjR49myZIl1KpVC4A2bdowePBg5s6dG9GN\nQcVVaEAPrPk4C7gIaA0MEpE8H5Wq+mdV7aCqHXCL3v4rGoU1xpSMcH1T0eqzqlatWu7zjRs38uCD\nD/L++++zZs0aevXqFXI8dqVKlXKfly9fnqysrJB5V65cudA0RVWvXj3WrFnDOeecw6xZsxg+fDgA\nS5YsYcSIEaxYsYIuXbpw5MgRX88bjpcaehdgk6puDqzgPR/oU0D6QcA8PwpnjImNWPZZ/fzzz9So\nUYOaNWuydetWlixZ4vs5unbtyoIFCwBYu3ZtyG8Awc4880yWLl1KZmYmWVlZzJ8/n27durF9+3ZU\nlf79+zN58mRWrVrFkSNHyMjIoGfPntx3333s2LGD/fnbr6LESxt6Y+C7oO0M4MxQCUWkOdACeL/4\nRTPGxEos+6w6depE69atadmyJc2bN6dr166+n+PGG2/kj3/8I61bt8595DSXhNKkSRPuvvtuunfv\njqpy6aWXcvHFF7Nq1Squu+46VBURYdq0aWRlZXHllVeyd+9esrOzufXWW6lRo4bv1xBKoWuKikg/\noJeqDg1sXwWcqaqjQqQdCzRR1RvD5DUMGAbQrFmzzt+EGodojImK9evX06pVq1gXo1TIysoiKyuL\nKlWqsHHjRi644AI2btxIhQqla5xIqPdMRFaqakqo9F5K/z3QNGi7SWBfKAOBsINAVXU2MBsgJSXF\nVqc2xsTEvn37OO+888jKykJVefTRR0tdMC8KL1ewAjhVRFrgAvlA4Mr8iUSkJVAH+NjXEhpjjM9q\n167NypUrY10M3xXaKaqqWcAoYAmwHligqutEZLKI9A5KOhCYr4W14RhjjIkKT98xVHUxsDjfvon5\ntif5VyxjjDGRiptb/40xxhTMAroxxiQIC+jGmBLRo0ePY24SmjlzJiNHjizwuOrVqwPwww8/0K9f\nv5BpunfvTlpaWoH5zJw5M88NPr///e99mWdl0qRJTJ8+vdj5+MECujGmRAwaNIj58+fn2Td//nwG\nDRrk6fhGjRrx0ksvFfn8+QP64sWLqV27dpHzK40soBtjSkS/fv1YtGhR7mIW6enp/PDDD5xzzjm5\n48I7depEu3bteO211445Pj09nbZt2wJw4MABBg4cSKtWrejbty8HDhzITTdy5MjcqXfvvPNOAB56\n6CF++OEHevToQY8ePQBISkpix44dAMyYMYO2bdvStm3b3Kl309PTadWqFddffz1t2rThggsuyHOe\nUFavXs1vfvMbkpOT6du3L7t27co9f850ujmTgn3wwQe5C3x07NiRvXv3Fvl3myP+R9IbYyJ2883g\n90I8HTpAIBaGVLduXbp06cKbb75Jnz59mD9/PgMGDEBEqFKlCq+88go1a9Zkx44d/OY3v6F3795h\n19V85JFHqFq1KuvXr2fNmjV5pr+dMmUKdevW5ciRI5x33nmsWbOG0aNHM2PGDJYuXUr9+vXz5LVy\n5Uqeeuopli9fjqpy5pln0q1bN+rUqcPGjRuZN28ejz32GAMGDODll18ucH7zP/7xjzz88MN069aN\niRMnctdddzFz5kymTp3Kli1bqFy5cm4zz/Tp05k1axZdu3Zl3759VKlSJYLfdmhWQzfGlJjgZpfg\n5hZVZfz48SQnJ3P++efz/fffs23btrD5LFu2LDewJicnk5ycnPvaggUL6NSpEx07dmTdunWFTrz1\n0Ucf0bdvX6pVq0b16tW57LLL+PDDDwFo0aIFHTp0AAqeohfc/Oy7d++mW7duAFx99dUsW7Yst4yp\nqanMmTMn947Url27MmbMGB566CF2797ty52qCVtD93v5LGMSSUE16Wjq06cPf/7zn1m1ahX79++n\nc+fOAMydO5ft27ezcuVKKlasSFJSUsgpcwuzZcsWpk+fzooVK6hTpw5DhgwpUj45cqbeBTf9bmFN\nLuEsWrSIZcuW8frrrzNlyhTWrl3LuHHjuPjii1m8eDFdu3ZlyZIltGzZsshlhQStoZfk8lnGGO+q\nV69Ojx49uPbaa/N0hu7Zs4fjjz+eihUrsnTpUgqbuO/cc8/l+eefB+Dzzz9nzZo1gJt6t1q1atSq\nVYtt27bx5ptv5h5To0aNkO3U55xzDq+++ir79+/nl19+4ZVXXuGcc86J+Npq1apFnTp1cmv3zz33\nHN26dSM7O5vvvvuOHj16MG3aNPbs2cO+ffv4+uuvadeuHWPHjuWMM87gyy+/jPic+SVkDb2kl88y\nxng3aNAg+vbtm2fES2pqKpdeeint2rUjJSWl0JrqyJEjueaaa2jVqhWtWrXKrem3b9+ejh070rJl\nS5o2bZpn6t1hw4bRq1cvGjVqxNKlS3P3d+rUiSFDhtClSxcAhg4dSseOHQtsXgnnmWeeYcSIEezf\nv5+TTjqJp556iiNHjjB48GD27NmDqjJ69Ghq167NHXfcwdKlSylXrhxt2rTJXX2pOAqdPjdaUlJS\ntLBxo0VVrpyrmecn4pavM6Yssulz40+k0+cmZJNLSS+fZYwxpUFCBvRYLp9ljDGxkpABPTUVZs+G\n5s1dM0vz5m7b2s9NWWezW8ePorxXcRfQ33oLBgwovC08NRXS01269HQL5sZUqVKFzMxMC+pxQFXJ\nzMyM+GajuBvlsnMnvPgiXHkl/OEPsS6NMfGjSZMmZGRksH379lgXxXhQpUoVmjRpEtExcTfKJSsL\nWrWCWrVgxQrXpGKMMWVFQo1yqVAB/vpXWLkS8s3EaYwxZVrcBXSAwYPdEMS77w493twYY8oiTwFd\nRHqJyAYR2SQi48KkGSAiX4jIOhF53t9i5lWpEowdC//9L3zwQTTPZIwx8aPQgC4i5YFZwEVAa2CQ\niLTOl+ZU4K9AV1VtA9wchbLmce210LAh3HNPtM9kjDHxwUsNvQuwSVU3q+ohYD7QJ1+a64FZqroL\nQFV/8reYx6pSBW67Dd57Dz7+ONpnM8aY0s9LQG8MfBe0nRHYF+w04DQR+Y+IfCIivUJlJCLDRCRN\nRNL8GDo1fDjUq1e8O0DnzoWkJDf/S1KSzchojIlffnWKVgBOBboDg4DHROSYxfpUdbaqpqhqSoMG\nDYp90mrVYMwYWLQI/ve/yI+3aXaNMYnES0D/HmgatN0ksC9YBrBQVQ+r6hbgK1yAj7obbnBj0otS\nSy9oml1jjIk3XgL6CuBUEWkhIpWAgcDCfGlexdXOEZH6uCaYzT6WM6xatWD0aHj5ZVi3LrJjv/02\nsv3GGFOaFRrQVTULGAUsAdYDC1R1nYhMFpHegWRLgEwR+QJYCtymqpnRKnR+N93kml/uvTey45o2\nDb3fptk1xsQjT23oqrpYVU9T1ZNVdUpg30RVXRh4rqo6RlVbq2o7VZ1fcI7+qlcP/vQnmDcPNm3y\ndsyRI9Co0bH7K1SwaXaNMfEpLu8UDWXMGHfD0dSphadVdc00n3wCV1xxdJrdatXca4FFvo0xJq4k\nTEBv2BCGDoVnnim8DfzOO+Ef/3Dj2OfPPzrN7pYtULu2y+fIkRIptjHG+CZhAjq4AC0C990XPs2D\nD7o5YK69FqZNy/tagwYwc6aruT/ySHTLaowxfkuogN6sGVx9NTz+OGzdeuzrzz0HN98MffvCo4+G\nnno3NRUuvNDN6GijXYwx8SShAjrAuHFw+DD87W9597/+OlxzDfTsCc8/7zo/QxGBf/7TNcGMHGmz\nORpj4kfCBfSTT3arGT3yCOzY4fYtW+aWrevYEV591c0DU5CkJDfSZfFieOGFqBfZGGN8kXABHVxz\nyYEDrj38f/+DSy91I1nefBNq1PCWx403whlnuNEwmSU2ot4YY4ouIQN669Zw+eXw8MPQq5e7m/Sd\nd6B+fe95lC/v2uJ37YJbboleWY0xxi8JGdDBzcfy88+uLfztt8PfFVqQ5GT4y1/cUMh33vG/jMYY\n46e4WyQ6Ei++CG3bukWli+rgQWjf3nW0rl3rbj4yxphYSahFoiPRv3/xgjm4DtTZs91NR5Mm+VIs\nY4yJioQO6H7p1s3Nkz5jBqxcGevSGGNMaBbQPZo2DWrWhLPOcmPVbXUjY0xpYwHdo0WL3OIXhw+7\nbVvdyBhT2lhA92jCBDh0KO8+W93IGFOaWED3yFY3MsaUdhbQPQq3ipGtbmSMKS0soHs0ZQpUrZp3\nX9WqtrqRMab08BTQRaSXiGwQkU0iMi7E60NEZLuIrA48hvpf1NhKTXXj0XOWratXz22npsa2XMYY\nk6PQgC4i5YFZwEVAa2CQiLQOkfQFVe0QeDzuczlLhdRU12ZetSpcdZUFc2NM6eKlht4F2KSqm1X1\nEDAf6BPdYpVe5ctDu3bw2WexLokxxuTlJaA3Br4L2s4I7MvvchFZIyIviUjIqbBEZJiIpIlI2vbt\n24tQ3NIhORnWrLHFL4wxpYtfnaKvA0mqmgy8AzwTKpGqzlbVFFVNadCggU+nLnnJyW6O9FDL3Blj\nTKx4CejfA8E17iaBfblUNVNVfw1sPg509qd4pVNysvu5Zk1sy2GMMcG8BPQVwKki0kJEKgEDgYXB\nCUTkxKDN3sB6/4pY+rRr535aQDfGlCaFBnRVzQJGAUtwgXqBqq4Tkcki0juQbLSIrBORz4DRwJBo\nFbg0qFPHLZgRLqDPnesm7ypXzibxMsaUnIRe4CKaLrnEDWHMH9TnznWTdu3ff3Rf1ao2Zt0Y448y\nu8BFNCUnw/r1x07YNWFC3mAONomXMaZkWEAvouRkyMqCL7/Mu98m8TLGxIoF9CIKN9LFJvEyxsSK\nBfQiOu00qFTp2IBuk3gZY2LFAnoRVagAbdocG9BzJvFq3twtVde8uXWIGmNKRoVYFyCeJSfD228f\nuz811QK4MabkWQ29GJKT3e3/cTwtjTEmgVhAL4acjtG1a2NbDmOMAQvoxZIT0G0qXWNMaWABvRiO\nPx5OOMHmdDHGlA4W0IspZ250Y4yJNQvoxdS+Paxb5+4aNcaYWLKAXkzJyfDrr7BxY6xLYowp6yyg\nF5MtdmGMKS0soBdTy5burtGiBnSbO90Y4xe7U7SYKld2Qb0oAT3/3OnffOO2we40NcZEzmroPijq\nSBebO90Y4ycL6D5ITnbzne/eHdlxNne6McZPngK6iPQSkQ0isklExhWQ7nIRUREJuTxSoirqFAA2\nd7oxxk+FBnQRKQ/MAi4CWgODRKR1iHQ1gJuA5X4XsrQr6kgXmzvdGOMnLzX0LsAmVd2sqoeA+UCf\nEOnuBqYBB30sX1xo1Ajq1o08oNvc6cYYP3kJ6I2B74K2MwL7colIJ6Cpqi4qKCMRGSYiaSKStj2B\n5pwVKXrHaGoqpKdDdrb7acHcGFNUxe4UFZFywAzglsLSqupsVU1R1ZQGDRoU99SlSnKya0PPzo51\nSYwxZZWXgP490DRou0lgX44aQFvg3yKSDvwGWFgWO0Z/+QW2bIl1SYwxZZWXgL4COFVEWohIJWAg\nsDDnRVXdo6r1VTVJVZOAT4DeqpoWlRKXUjY3ujEm1goN6KqaBYwClgDrgQWquk5EJotI72gXMF60\naePa0m1OF2NMrHi69V9VFwOL8+2bGCZt9+IXK/5UrQqnnmoB3RgTO3anqI9ssQtjTCxZQPdRcjJ8\n/TXs2xfrkhhjyiIL6D7K6Rj9/HPvx2RlwW23wYcfRqdMxpiywwK6j9q3dz8jaXa57z6YPh0GD4YD\nB6JTLmNM2WAB3UfNm0ONGt4D+qpVcOedcMYZbobF6dOjWz5jTGKzgO6jSKYAOHAArroKjj8e3noL\n+vWDe++F774r/FhjjAnFArrPcgK6asHpxo+HL76Ap55yE3vdf787ZuzYkimnMSbxWED3WXIy7NlT\ncE37vfdg5kwYNQouuMDtS0pynaPz5sFHH5VIUY0xCcYCus8Kmxt9924YMgROPx2mTcv72tix0KQJ\n3HQTHDmS9zVbTNoYUxgL6D5r29b9DBfQR42CrVvhueeOXdyiWjU36mXVKnj66aP7cxaT/uYb1yyT\ns5i0BXVjTDAL6D6rWRNatAgd0BcscEF44kQ3siWUgQOha1fXxr5nj9tni0kbY7ywgB4FoUa6/PAD\njBgBXbq4YB2OCDz4IGzfDnff7fbZYtLGGC8soEdBcjJs2HD0RiFVuPZaOHjQNbVUKGRKtM6dXfoH\nH3T52GLSxhgvLKBHQXKyW7noiy/c9iOPwJIl7sah007zlseUKXDccXDLLbaYtDHGGwvoURA80mXD\nBrj1VrjwQhg50nseJ5zg2toXLXLj1G0xaWNMYUQLuwMmSlJSUjQtLTEXNTpyxE0BcO218OmnbgbG\ntWuhUaPI8jl0yI2aKVfOfThUqhSd8hpj4oeIrFTVkEt8Wg09CsqXd4F49mxYsQL++c/Igzm4AP7A\nA66WP2uW/+U0xiQWC+hRkpwMhw+7WRT79y96PhdfDBddBJMmwU8/eTvGbkIypmzyFNBFpJeIbBCR\nTSIyLsTrI0RkrYisFpGPRKS1/0WNL337wrnnwsMPFz+vGTPcuPPbby88rd2EZEzZVWgbuoiUB74C\nfgdkACuAQar6RVCamqr6c+B5b+BPqtqroHwTuQ09GsaMcfO/pKVBp07h0yUluSCeX/PmkJ4erdIZ\nY0pKcdvQuwCbVHWzqh4C5gN9ghPkBPOAakBseloT2MSJUL++m+eloM9guwnJmLLLS0BvDATPHZgR\n2JeHiNwgIl8D9wGj/SmeyVG7tgvqH30Ey5eHT2c3IRlTdvnWKaqqs1T1ZGAsELK1V0SGiUiaiKRt\n377dr1OXGVdfDdWru1Ez4dhNSMaUXV4C+vdA06DtJoF94cwH/hDqBVWdraopqprSoEED76U0gBvb\nnpoKL7wAu3aFTpOaajchGVNWeQnoK4BTRaSFiFQCBgILgxOIyKlBmxcDG/0rogk2fPjROWHCSU11\nHaDZ2e6nBXNjyoZCA7qqZgGjgCXAemCBqq4TkcmBES0Ao0RknYisBsYAV0etxGVcx45u6t1HHy18\nmTtjTNlSyLx/jqouBhbn2zcx6PlNPpfLFGDECLjuOvjPf+Dss2NdGmNMaWF3isahK65wC2kU1Dnq\nt59/hnbtYM6ckjunMSYyFtDjULVqcNVV8NJLkJlZMue85x74/HN4/fWSOZ8xJnIW0OPU8OHw66/w\nzDPRP9emTe4uVYCVK6N/PmNM0VhAj1Pt2sFvf1synaO33gqVK8ONN7qpgMMNmTTGxJYF9Dg2fDh8\n9RX8+9/RO8d778Frr7l1UC+91O1btSp65zPGFJ0F9DjWvz/UqeNq6dGQlQU33wwtWsCf/3x0UjBr\ndjGmdLKAHseOO85NB/Cvf3mfKz0Sjz3mOkLvvx+qVIF69dxsjhbQjSmdLKDHuWHD3EIaTz/tb767\ndsEdd0C3bnDZZUf3d+7spvA1xpQ+FtDjXKtWbiGN2bPdrf5+mTwZdu50o1tEju5PSYHNm61j1JjS\nyAJ6Ahg+3I0+ee+9yI4Lt1Tdl1/C3/8OQ4dChw55j+nc2f20jlFjSh8L6Ang8svd4heRdI4WtFTd\nLbe4KXfvuefY46xj1JjSy9NcLqZ0q1wZhgxxzSM//ggNGxZ+zIQJbp3SYPv3u6XufvrJdYQef/yx\nx+V0jFo7ujGlj9XQE8SwYVbw1jwAABUBSURBVG6Y4ZNPeksfbkm6n36CU06B0QWsOZWSYjV0Y0oj\nC+gJ4tRToWdP1zl65Ejh6Qtaku5vf4NKlfLuC25vf/dd6xg1pjSygJ5ARoxwbeFvv1142lBL1QG0\nbXv0jtAc+dvbd+92+++7r/hlNsb4xwJ6AunTx7V7e+kczb9UXY0a7ue8eXmHKULo9nYo2el7jTGF\ns4CeQCpVgmuvhTfegO8LWvU1IGepurVrXcAeOdLV0PML196eU1M3xpQOFtATzPXXuzb0J57wll7V\nzdNSowbcdVfoNOHa2yvYGCljShX7l0wwJ50EF17o5mEZP/5o0D1yBLZtczX3nEdGhrsh6Z133JDH\n+vVD5zllimtDD252qVjRTTmwa5ebIMwYE3ueArqI9AIeBMoDj6vq1HyvjwGGAlnAduBaVf3G57Ia\nj4YPd/OvXHgh/PKLC95btx47+qVCBTjxRBg4EP70p/D5paa6nxMmuOaXZs3cMdOmueGL558fvWsx\nxngnWsjqCCJSHvgK+B2QAawABqnqF0FpegDLVXW/iIwEuqvqFQXlm5KSoml2d0pUHD4M550HO3ZA\n48ZHH02a5N0+/ng3DLEodu50NxlNnQpjx/pbfmNMeCKyUlVTQr3mpYbeBdikqpsDmc0H+gC5AV1V\nlwal/wQYXPTimuKqWBGWLYvuOerWdfOk57/BaO7cvDX5KVOO1vCNMdHlpX7WGPguaDsjsC+c64A3\nQ70gIsNEJE1E0rZv3+69lKZU6tw5b0AvaH4YY0z0+TrKRUQGAynA/aFeV9XZqpqiqikNGjTw89Qm\nBjp3dneM7tzptsPNDzNhQsmXzZiyyEtA/x5oGrTdJLAvDxE5H5gA9FbVX/0pninNUgKteDlT6YYb\nrx5uvzHGX14C+grgVBFpISKVgIHAwuAEItIReBQXzKOwGJopjfJPpRtuvHpB88YYY/xTaEBX1Sxg\nFLAEWA8sUNV1IjJZRHoHkt0PVAdeFJHVIrIwTHYmgeTvGA01P0zVqm5/KOEW2DDGFI2nceiquhhY\nnG/fxKDnNhK5jApeYzTUePVwo1xyOlBz2txzOlCD8zHGRKbQcejRYuPQE8O0aTBuHGRmuhq7V0lJ\nLojn17y5m1/GGBNaQePQbS4XUyxFXWPUOlCN8Z8FdFMsRV1j1DpQjfGfBXRTLHXrugnBIg3okXag\nemUdraYss4Buii24Y9Sr/AtsNG/utovTIWp3qpqyzgK6KbbOnWHLlqN3jHqVs8BGdrb7GS6Ye611\n252qpqyzgG6Kragdo15EUuu2jlZT1llAN8WWE9AjbUf3IpJat3W0mrLOAroptjp1XMdoNG4riKTW\nHa2OVmPihQV044v8U+n6JZJadzQ6Wo2JJxbQjS+K2jFamEhr3V47Wo1JRBbQjS/yT6XrF6t1G+Od\nBXTji5w7RqPRjm61bmO88TTbojGFyekYjUY7uh9++cU1CW3e7H7mPOrUgSefLPpi2caUJhbQjW+K\ncsdoNCxcCB9/nDdw51/Ctlo1aNgQvv4aLrwQBg2KTVmN8ZMFdOOblBR48UXXMRrJVLp+mj0bhg+H\nChVce3uLFvCHP7ifLVq4bxEtWkD9+u5GpY4d4Y47oF8/qFgxNmU2xi8W0I1vgm8w+t3vSv78770H\nN9wAvXq5WnpBAXruXHdzUs6c7CNGwBNPlEw5jYkWazk0vinqVLp++PJLuPxyOP10eOGFwoN5znQC\nOZ56yj1Kitf5aWz2SBMJTwFdRHqJyAYR2SQi40K8fq6IrBKRLBHp538xTTyIVcfojh1wySVQuTK8\n8QbUrFlw+lDTCajCLbcUrxxz58IJJxwdXllQkPYyP43NHmkipqoFPoDywNfASUAl4DOgdb40SUAy\n8CzQr7A8VZXOnTurSTwDBqi2aFFy5zt4UPWcc1QrV1b973+9HSOi6kLksY89e4pWjjlzVKtUyZtX\n1apuf37Nm4c+d/PmRUtnyhYgTcPEVS819C7AJlXdrKqHgPlAn3wfCumqugbI9uVTxsStnDtGMzOj\nfy5VV2P98EN4+mk46yxvxxU0WdeMGUUry/jxcPBg3n3hJhHzOj+NzR5pIuUloDcGvgvazgjsi5iI\nDBORNBFJ255/HJlJCNGcSje/qVPh2Wdh0iQYOND7ceGmEzjjDPjb31wTTqQiCb5e56eJdPZIa283\nJdopqqqzVTVFVVMaNGhQkqc2JaSkOkZfesnViq+8EiZOjOzYcNMJPPOMq1Xfe2/e9IUFyv/9L/y5\nQgVfr/PTRDKPjbW3G8BTG/pZwJKg7b8Cfw2T9mmsDb3MO/lk1X79opf/p5+69uqzzlI9cMDfvIcM\nce3x333ntufMcW3h4drG9+9Xbd1atXZt1eOOy5tORPW550KfZ84c1xYu4n6GamuPJJ21t5cdFNCG\n7iWgVwA2Ay042inaJkxaC+hGBwxwgSQ72/+8v/1WtWFD1aQk1W3b/M9/yxbVihVVr7/ebRcWKEeP\ndttLluQNvvXquf3vv+9/GUMJ19ErUjLn9/rBY4qvWAHdHc/vga9wo10mBPZNBnoHnp+Ba1v/BcgE\n1hWWpwX0xPXEE+4va+ZMf/Pdu1e1fXvVmjVVP//c37yDjRqlWr686ldfFRwo337bPR89+tg89u9X\nrVPHfbiVhFjW0Av7FmP8VeyAHo2HBfTElZ2t+oc/qFaooLpsmT95ZmWpXnKJarlyqm+95U+e4Wzd\n6gLSoEHhA2WTJqqNGrnmlv37Q+dz882uth+NbxL5RRJU58xRbdr0aMAvKPB6qXlH+mFitfnisYBu\nStzu3aqnneaaR374oXh5ZWerjhzp/lr//nd/yleYv/7VnW/KlGMD5XHHqXbp4oL1qlXh8/jiC5d+\n6tSSKbOXQBlqvHzlyqHb+r1+SETS3BPr2nwifJhYQDcx8fnn7p/17LNVDx0qWh7Z2apjxri/1Ntu\n87d8Bdm503V0XnLJsUFg+HDvgbpbN9WTTlI9ciTKBfaoUaPQwbdyZdVFi/L2e0TjBqhoNQ1lZroP\n2VGjVH/8MXSaWH+Y+MUCuomZefPcX9lNNxXt+Ntvd8ffeGN0OlkL8n//58790UdH923Zolqjhrs7\nNSur8Dyef15zO01j7ZNPQgfT4Ef79qovvOCuzWvNO5JAGa3O2zFjXB7ly6tWq6Y6ceKxd/0mykgg\nC+gmpm6+2f2lPf98ZMdNmeKOGzo0NjXcfftUTzhB9dxz3YdJVpYL5DVquMDuxcGDqvXrq152WVSL\nWqg333RBtkKF0EGtWTPVp59WPf10t33qqUdH6ngJgLEcXrl5s2qlSqrXXKO6YYNq//4uz/r1Xcf8\nwYMuXaxHAvnFArqJqUOHXCCsWlV17Vpvx8yY4f46Bw/2VhOOlocfduV46y3Ve+91z599NrI8brvN\n1Ry//z46ZSzMs8+6QN6hg+uDKKg2nZWl+tJLqh07Hg12+fsPitNEEWnnrZcPiUGDXLkyMo7u+/RT\n1Z49Xf5JSe530KxZ7GvofrThW0A3Mbd1q+qJJ7qa3+7dBaf9xz/cX2b//qqHD5dM+cI5eND9451y\niusE7d8/8qafjRvd9dx9d1SKWKDp0925e/Y82gThJahkZ7tafU6NPedRoYILkL/9rbt5bPRo15fw\n7LOq774bvv06mNfOWy+Bf8UK99qECaGvYcmSox9OzZq5vgKvbeh+3/zlVxu+BXRTKnz4oQsIffqE\nb0J58kn3V3nppUXvSPXb00+7MjVq5DrfiuK881xAKcq3jQMHVD/7LLLfx5Ejqrfe6srdr9/RZoei\nWL1a9cUXVR98UHXsWNWrrnLX06qVuycgf4B6++2inyuHl6aZ7GzX6dyggers2eGD6pEjri/n5JNd\nHjlB3Y/gG0mQ9qu5yQK6KTUefND91f3f/x372vPPu3/ICy7w/5b+4sjKcsHx44+LnseLL7rrfuON\nyI7LzFTt1OlooDjvPNVJk9wdqL/8EvqYQ4dc0AXVG26IfpPV3r3uJqz33lNNTnbfZF56qXh5emnv\nXrjQ7bv6am9B9ddfVWfNcv0ilSur/uc/4c8fjRE+frXhW0A3pUZ2tuqVV7obhIJrci+/7NqZu3cP\nH6ji2aFDLpBceqn3Y3KCeaVKrulk9GjXDp4TGCpWdPPZ/OUv7oNi1y7XkXvRRZrbxFPSI4N27nTN\nMeXKuTuGi6qwQHn4sGrLlu5eh0jbxnfscE1o9eurfv116DReg28kQdpq6CYh7dun2ratG0WRnu7G\nP+cEp717Y1266Bk/3gW6b78tPG1wMF+8OO9ru3a539m4cS54Vqx4NIjUq+fOMXt2dK7Bi337VHv1\ncmW6//6i5VFYU8Y//+n2/etfRav5btigWreu+1DYufPY16NRQ7c2dJOwvvrKtb+2bOm+/nbuXHhn\nabzbssUFmYkTC05XUDAPZf9+1aVLVSdPdsMjFy70o7TF8+uvbh4bcHfdFuWbQrjOxr173bedrl1d\nvkWt+X7wgfsw7NnTlTf/uf1uQy/omiJhAd2USq+95v4C27VzX4PLgl69XOdquNE7kQbz0iwrS3XY\nMPcejxjhX1v+nXe6PHP6NIpT833mGZf+2muP/dDxe5SLXyygm1Lrk09cE0JZ8eqr7r/u1VePfS2R\ngnmO7GzXNASqV1xxbE04Uj/84IJ1//559xcnqN5xhyvfvfcWr2wlxQK6MaXE4cOqjRu7mnqwRAzm\nwaZNc9HmoouK1+l9/fWumWTTJv/Klp3tbk4CNxqptCsooJfoEnTGlHUVKsB118GSJZCe7vbt3Am/\n+x18/jm8+ipcdFFMixgVf/mLW+bvrbfgggtg9+7I81i3Dp54AkaOhJNP9q9sIvDkk/Db38JVV8Hy\n5f7lXdIsoBtTwoYOdUHkscfKRjDPcf318MIL8Omn0L07fPVVZMePHQvVq8Mdd/hftipV3O+/USPo\n3fvoh228sYBuTAlr2hQuvtjVNstKMM/Rvz+88QZs2gSnnw6XXALvvuu6MguydCksWuQWBq9fPzpl\na9DAnePQIff+7NkTnfPs2QP79kUnbwvoxsTA8OGwbVvZCuY5LrjABfQ774QVK9yHWrt28PjjcODA\nsemzs+G229wH4ejR0S1by5bw8svu20P//nD4cPHz3LkTXnsNxoyBzp2hbl148cXi5xtSuMb14AfQ\nC9gAbALGhXi9MvBC4PXlQFJheVqnqCnLsrLctMLvvBPrksTWgQOqTz3l5mEHd2PUhAl5Z6acO9e9\nFuksl8WRM6fQsGGRj6Hfts11ro4a5Ybk5gylrFLF3Ql9553FWxOXAjpFRQv5riMi5XELRP8OtxD0\nCmCQqn4RlOZPQLKqjhCRgUBfVb2ioHxTUlI0LS2tKJ9BxpgEowoffAAzZ8LChVC+PFxxhesATU11\ntdq0NChXgm0K48fDvfdCxYpQo0bBj+rVXU182TJYv94dX7UqdO0K3brBuedCly5QuXLxyyUiK1U1\nJeRrHgL6WcAkVb0wsP1XAFW9NyjNkkCaj0WkAvAj0EALyNwCujEmlK+/hr//3fUx7N3r9r37Lpx3\nXsmWIzsbnnrKNQ/t3Vv4o1o1OPvsowG8c2f3YeC3ggJ6BQ/HNwa+C9rOAM4Ml0ZVs0RkD1AP2JGv\nIMOAYQDNmjXzVHhjTNly8snwwANw110uoB44UPLBHNy3geuu85Y2p+oqEr3yeOEloPtGVWcDs8HV\n0Evy3MaY+FKzJtx0U6xL4U2sA3kOLy1S3wNNg7abBPaFTBNocqkFZPpRQGOMMd54CegrgFNFpIWI\nVAIGAgvzpVkIXB143g94v6D2c2OMMf4rtMkl0CY+ClgClAeeVNV1IjIZN3xmIfAE8JyIbAJ24oK+\nMcaYEuSpDV1VFwOL8+2bGPT8INDf36IZY4yJhN0paowxCcICujHGJAgL6MYYkyAsoBtjTIIo9Nb/\nqJ1YZDvwTb7d9cl3d2mcS7TrgcS7pkS7Hki8a0q064HiXVNzVW0Q6oWYBfRQRCQt3BwF8SjRrgcS\n75oS7Xog8a4p0a4HondN1uRijDEJwgK6McYkiNIW0GfHugA+S7TrgcS7pkS7Hki8a0q064EoXVOp\nakM3xhhTdKWthm6MMaaILKAbY0yCKBUBXUR6icgGEdkkIuNiXR4/iEi6iKwVkdUiEpdr7YnIkyLy\nk4h8HrSvroi8IyIbAz/rxLKMkQhzPZNE5PvA+7RaRH4fyzJGQkSaishSEflCRNaJyE2B/fH8HoW7\nprh8n0Skioh8KiKfBa7nrsD+FiKyPBDzXghMTV7888W6Dd3LItTxSETSgRRVjdsbIkTkXGAf8Kyq\ntg3suw/YqapTAx++dVR1bCzL6VWY65kE7FPV6bEsW1GIyInAiaq6SkRqACuBPwBDiN/3KNw1DSAO\n3ycREaCaqu4TkYrAR8BNwBjgX6o6X0T+CXymqo8U93yloYbeBdikqptV9RAwH+gT4zIZQFWX4ea3\nD9YHeCbw/BncP1tcCHM9cUtVt6rqqsDzvcB63Pq+8fwehbumuKTOvsBmxcBDgZ7AS4H9vr1HpSGg\nh1qEOm7fwCAKvC0iKwOLYyeKE1R1a+D5j8AJsSyMT0aJyJpAk0zcNE8EE5EkoCOwnAR5j/JdE8Tp\n+yQi5UVkNfAT8A7wNbBbVbMCSXyLeaUhoCeqs1W1E3ARcEPg635CCSwzGO/jXh8BTgY6AFuBv8W2\nOJETkerAy8DNqvpz8Gvx+h6FuKa4fZ9U9YiqdsCtx9wFaBmtc5WGgO5lEeq4o6rfB37+BLyCeyMT\nwbZAO2dOe+dPMS5PsajqtsA/XDbwGHH2PgXaZV8G5qrqvwK74/o9CnVN8f4+AajqbmApcBZQW0Ry\nVozzLeaVhoDuZRHquCIi1QIdOohINeAC4POCj4obwQuCXw28FsOyFFtO4AvoSxy9T4EOtyeA9ao6\nI+iluH2Pwl1TvL5PItJARGoHnh+HG/yxHhfY+wWS+fYexXyUC0BgCNJMji5CPSXGRSoWETkJVysH\nt27r8/F4TSIyD+iOm+pzG3An8CqwAGiGm/54gKrGRUdjmOvpjvsar0A6MDyo/blUE5GzgQ+BtUB2\nYPd4XJtzvL5H4a5pEHH4PolIMq7TszyuAr1AVScHYsR8oC7wP2Cwqv5a7POVhoBujDGm+EpDk4sx\nxhgfWEA3xpgEYQHdGGMShAV0Y4xJEBbQjTEmQVhAN8aYBGEB3RhjEsT/A06Gm3YF4rckAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-KfyWrPOL2W",
        "colab_type": "code",
        "outputId": "83618ebe-5c96-453b-b029-e9c803918c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 74, 74, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 74, 74, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 32)   9216        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 32)   96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 32)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 72, 72, 64)   18432       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 72, 72, 64)   192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 72, 72, 64)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 35, 35, 80)   240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 35, 35, 80)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 33, 33, 192)  138240      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 33, 33, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 33, 33, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   55296       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 48)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   76800       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 96)   82944       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 64)   192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 32)   96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 96)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 32)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_100[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 64)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   55296       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 48)   144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 48)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   76800       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 96)   82944       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 64)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 96)   288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 96)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 64)   192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   55296       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 48)   144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 48)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   76800       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 96)   82944       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 64)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 96)   288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 64)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 96)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_114[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 64)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 96)   55296       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 96)     82944       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 7, 7, 384)    1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 96)     288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 7, 7, 384)    0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 96)     0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 128)    114688      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 128)    114688      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 128)    384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 128)    384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 128)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 128)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 192)    172032      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    172032      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 160)    179200      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 160)    179200      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 160)    480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 160)    480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 160)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 160)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 192)    215040      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 192)    576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 192)    576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 192)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 192)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_135[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 160)    179200      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 160)    179200      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 160)    480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 160)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    215040      activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    258048      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    258048      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_155[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 7, 7, 192)    258048      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 7, 7, 192)    576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 7, 7, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 7, 7, 192)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 7, 7, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 3, 3, 320)    552960      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 192)    331776      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 3, 3, 320)    960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 192)    576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 3, 3, 320)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 192)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_166[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 448)    1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 448)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    1548288     activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 384)    1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 384)    1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 384)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 384)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_173[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_177[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 192)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_171[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 448)    1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 448)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    1548288     activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 384)    1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 384)    1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 320)    960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 384)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 384)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 320)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_180[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_188[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uByUG_dvxK9T",
        "colab_type": "code",
        "outputId": "62a998a1-e174-4fba-9ebd-70fcf6ace4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1045 images belonging to 2 classes.\n",
            "test acc: 0.9989999997615814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NOF39wOXvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGtsgng_OmgP",
        "colab_type": "code",
        "outputId": "528688bd-ab0d-4e34-fc7d-cf722562c02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"Inception_v3 - Raw - CNN.h5\", \n",
        "                             monitor='val_acc', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=False, \n",
        "                             mode='auto', period=1)\n",
        "\n",
        "early = EarlyStopping(monitor='val_acc', \n",
        "                      min_delta=0, \n",
        "                      patience=20, \n",
        "                      verbose=1, \n",
        "                      mode='auto')\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "    metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,\n",
        "    callbacks = [checkpoint, early])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 54s 542ms/step - loss: 0.0468 - acc: 0.9855 - val_loss: 0.0078 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.99700, saving model to Inception_v3 - Raw - CNN.h5\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 42s 418ms/step - loss: 0.0396 - acc: 0.9859 - val_loss: 0.0211 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.99700\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 0.0383 - acc: 0.9845 - val_loss: 0.0081 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.99700\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 0.0396 - acc: 0.9860 - val_loss: 0.0150 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.99700\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 43s 429ms/step - loss: 0.0329 - acc: 0.9880 - val_loss: 0.0049 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.99700 to 0.99800, saving model to Inception_v3 - Raw - CNN.h5\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 43s 434ms/step - loss: 0.0336 - acc: 0.9880 - val_loss: 0.0108 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99800\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.0068 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99800\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 0.0322 - acc: 0.9875 - val_loss: 0.0118 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99800\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 45s 445ms/step - loss: 0.0465 - acc: 0.9864 - val_loss: 0.0098 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99800\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0119 - val_acc: 0.9950\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99800\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 0.0313 - acc: 0.9870 - val_loss: 0.0102 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99800\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.0305 - acc: 0.9895 - val_loss: 0.0069 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99800\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.0346 - acc: 0.9905 - val_loss: 0.0116 - val_acc: 0.9950\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99800\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 0.0286 - acc: 0.9890 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.99800 to 0.99800, saving model to Inception_v3 - Raw - CNN.h5\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 0.0305 - acc: 0.9885 - val_loss: 0.0115 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99800\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 45s 445ms/step - loss: 0.0356 - acc: 0.9859 - val_loss: 0.0055 - val_acc: 0.9990\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.99800 to 0.99900, saving model to Inception_v3 - Raw - CNN.h5\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 0.0262 - acc: 0.9905 - val_loss: 0.0041 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99900\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0088 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99900\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 0.0359 - acc: 0.9895 - val_loss: 0.0077 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99900\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 0.0262 - acc: 0.9894 - val_loss: 0.0057 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99900\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 43s 426ms/step - loss: 0.0427 - acc: 0.9870 - val_loss: 0.0101 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99900\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 43s 429ms/step - loss: 0.0333 - acc: 0.9885 - val_loss: 0.0045 - val_acc: 0.9990\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99900\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.0060 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99900\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 43s 433ms/step - loss: 0.0392 - acc: 0.9860 - val_loss: 0.0070 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99900\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 44s 435ms/step - loss: 0.0339 - acc: 0.9900 - val_loss: 0.0065 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99900\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 0.0362 - acc: 0.9857 - val_loss: 0.0064 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99900\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 0.0317 - acc: 0.9875 - val_loss: 0.0108 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99900\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 43s 427ms/step - loss: 0.0223 - acc: 0.9920 - val_loss: 0.0058 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99900\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 43s 432ms/step - loss: 0.0332 - acc: 0.9895 - val_loss: 0.0107 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99900\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 43s 426ms/step - loss: 0.0398 - acc: 0.9850 - val_loss: 0.0044 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99900\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 0.0358 - acc: 0.9865 - val_loss: 0.0059 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99900\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 0.0334 - acc: 0.9885 - val_loss: 0.0068 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99900\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.0243 - acc: 0.9945 - val_loss: 0.0104 - val_acc: 0.9970\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99900\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 0.0248 - acc: 0.9915 - val_loss: 0.0066 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99900\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 42s 424ms/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0069 - val_acc: 0.9950\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99900\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 43s 429ms/step - loss: 0.0278 - acc: 0.9894 - val_loss: 0.0070 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99900\n",
            "Epoch 00036: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA7GpfhVO41F",
        "colab_type": "code",
        "outputId": "e16da2b7-a9b6-47cd-c20a-a729d30d8c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "def smooth_curve(points, factor=0.1):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "        smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "plt.plot(epochs,\n",
        "  smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
        "plt.plot(epochs,\n",
        "  smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,\n",
        "  smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
        "plt.plot(epochs,\n",
        "  smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcbECQvoxhgTJyygG2NMnPh/N0IXSSXLNCgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eardsd0WpHzA",
        "colab_type": "code",
        "outputId": "81418d32-02ca-4e50-f99f-b90aa19f6551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1045 images belonging to 2 classes.\n",
            "test acc: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjxmmPdfyWX4",
        "colab_type": "code",
        "outputId": "dbe7f682-d5ec-4fbb-ffb9-b47c057dd090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load_model_sample.py\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # load model\n",
        "    model = load_model(\"Inception_v3 - Raw - CNN.h5\")\n",
        "\n",
        "    # image path\n",
        "    # img_path = '/content/Drive/My Drive/Colab Notebooks/data01/Test/mdb226.jpg'    # benign\n",
        "    img_path = '/content/Drive/My Drive/Colab Notebooks/data01/Test/mdb241.jpg'      # malignant\n",
        "\n",
        "    # load a single image\n",
        "    new_image = load_image(img_path)\n",
        "\n",
        "    # check prediction\n",
        "    pred = model.predict(new_image)\n",
        "    print (pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999989]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgkD9IKgn_Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_CRuo_epkzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}